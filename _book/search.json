[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Welcome Quantitative Methods - R Cookbook. cookbook covers practical worked examples can easily apply dataset also includes discussion recipe working. cover descriptive basic inferential statistics, including graphs, frequency distributions, central tendency, dispersion, probability, hypothesis testing, tests mean differences, correlation simple regression, chi-square tests. cookbook designed facilitate graduate post graduate students develop knowledge understanding various statistical concepts procedures R programming.","code":""},{"path":"index.html","id":"general-objectives","chapter":"Welcome","heading":"General Objectives","text":"course based upon 3 credit semester course “Quantitative Methods” taught University OKlahoma Fall 2022. Based course, objectives cookbook :able correctly identify variables falling different scales measurement.able correctly identify variables falling different scales measurement.able correctly identify appropriate techniques analyzing data presented variables different measurement characteristics.able correctly identify appropriate techniques analyzing data presented variables different measurement characteristics.able understand assumptions associated different statistical tests.able understand assumptions associated different statistical tests.able set manage databases containing variables.able set manage databases containing variables.able carry statistical analyses data using R.able carry statistical analyses data using R.able correctly interpret results statistical analyses.able correctly interpret results statistical analyses.able distinguish null alternative (research) hypotheses.able distinguish null alternative (research) hypotheses.able distinguish directional non-directional hypothesis.able distinguish directional non-directional hypothesis.understand concepts “statistical significance” “effect size”.understand concepts “statistical significance” “effect size”.understand effects sampling (e.g., size, strategies) inferences concerning population estimates.understand effects sampling (e.g., size, strategies) inferences concerning population estimates.","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"acknolwedgement","chapter":"Preface","heading":"0.1 Acknolwedgement","text":"like thank professor Dr C providing wonderful opportunity ocmpile resource materials R.","code":""},{"path":"preface.html","id":"conventions-used-in-the-book","chapter":"Preface","heading":"0.2 Conventions Used in the Book","text":"Code chunks presented typical Markdown format , code output :{runif(n = 20, min = 0, max = 100)}Finally, R version currently using:","code":"\nversion\n#>                _                                \n#> platform       x86_64-w64-mingw32               \n#> arch           x86_64                           \n#> os             mingw32                          \n#> crt            ucrt                             \n#> system         x86_64, mingw32                  \n#> status                                          \n#> major          4                                \n#> minor          2.2                              \n#> year           2022                             \n#> month          10                               \n#> day            31                               \n#> svn rev        83211                            \n#> language       R                                \n#> version.string R version 4.2.2 (2022-10-31 ucrt)\n#> nickname       Innocent and Trusting"},{"path":"preface.html","id":"rdrr-live-r-console","chapter":"Preface","heading":"0.3 RDRR (Live R console)","text":"","code":""},{"path":"preface.html","id":"example-data","chapter":"Preface","heading":"0.4 Example Data","text":"","code":""},{"path":"preface.html","id":"additional-resources","chapter":"Preface","heading":"0.5 Additional Resources","text":"","code":""},{"path":"basic-statistical-concepts.html","id":"basic-statistical-concepts","chapter":"1 Basic Statistical Concepts","heading":"1 Basic Statistical Concepts","text":"","code":""},{"path":"basic-statistical-concepts.html","id":"data-types","chapter":"1 Basic Statistical Concepts","heading":"1.1 Data Types","text":"Data types idea computer science program shares similar nomenclature case statistics. Data broadly classified constant variables terms nature execution analysis statistical program.Constant kind data types changed program analysis. eg, value alpha (alpha) always kept constant.Variables data types changed multiple values program.","code":""},{"path":"basic-statistical-concepts.html","id":"types-of-variable","chapter":"1 Basic Statistical Concepts","heading":"1.2 Types of variable","text":"Quantitative Variables (Continuous Discrete):\nContinuous Variables: Variables can take value within range, typically measured continuous scale. Example: Height, weight, temperature.\nDiscrete Variables: Variables can take specific values, usually whole numbers counts. Example: Number students class, number books library.\nQuantitative Variables (Continuous Discrete):Continuous Variables: Variables can take value within range, typically measured continuous scale. Example: Height, weight, temperature.Continuous Variables: Variables can take value within range, typically measured continuous scale. Example: Height, weight, temperature.Discrete Variables: Variables can take specific values, usually whole numbers counts. Example: Number students class, number books library.Discrete Variables: Variables can take specific values, usually whole numbers counts. Example: Number students class, number books library.Qualitative Variables (Nominal Ordinal):\nNominal Variables: Variables represent categories without inherent order. Example: Gender (male female), types food (vegetarian non-vegetarian).\nOrdinal Variables: Variables represent categories natural order ranking. Example: Education level (elementary, high school, college), customer satisfaction ratings (poor, average, excellent).\n                   VARIABLES\n                       |\n            +----------+-----------+\n            |                      |\n      Quantitative           Qualitative\n            |                      |\n     +------+-------+      +-------+-------+\n     |              |      |               |\nContinuous    Discrete   Nominal      Ordinal\nUnderstanding types variables crucial guides selection appropriate statistical techniques data analysis.\nQualitative Variables (Nominal Ordinal):Nominal Variables: Variables represent categories without inherent order. Example: Gender (male female), types food (vegetarian non-vegetarian).Nominal Variables: Variables represent categories without inherent order. Example: Gender (male female), types food (vegetarian non-vegetarian).Ordinal Variables: Variables represent categories natural order ranking. Example: Education level (elementary, high school, college), customer satisfaction ratings (poor, average, excellent).\n                   VARIABLES\n                       |\n            +----------+-----------+\n            |                      |\n      Quantitative           Qualitative\n            |                      |\n     +------+-------+      +-------+-------+\n     |              |      |               |\nContinuous    Discrete   Nominal      Ordinal\nUnderstanding types variables crucial guides selection appropriate statistical techniques data analysis.Ordinal Variables: Variables represent categories natural order ranking. Example: Education level (elementary, high school, college), customer satisfaction ratings (poor, average, excellent).Understanding types variables crucial guides selection appropriate statistical techniques data analysis.","code":"                   VARIABLES\n                       |\n            +----------+-----------+\n            |                      |\n      Quantitative           Qualitative\n            |                      |\n     +------+-------+      +-------+-------+\n     |              |      |               |\nContinuous    Discrete   Nominal      Ordinal"},{"path":"basic-statistical-concepts.html","id":"types-of-scales-of-measurement-of-variables","chapter":"1 Basic Statistical Concepts","heading":"1.3 Types of scales of measurement of variables","text":"Four different types scales measurement presented table .Understanding scales measurement important helps determine appropriate statistical techniques interpretations data.","code":""},{"path":"r-basics.html","id":"r-basics","chapter":"2 R Basics","heading":"2 R Basics","text":"sections covers everything need get run statistical analysis using R. Just like programming language, R also base package Integrated Development Environment. Base package need run R code computer. R Studio IDE developed specifically focussing development R programs packages.","code":""},{"path":"r-basics.html","id":"installing-r-base-package.","chapter":"2 R Basics","heading":"2.1 Installing R base package.","text":"R base package can downloaded official website R. , enter inside website select package operating system, download file install . ensure R successfully installed, able run command prompt terminal using R command. Type q() quit R console.","code":"$ R\n\nR version 4.2.1 (2022-06-23 ucrt) -- \"Funny-Looking Kid\"\nCopyright (C) 2022 The R Foundation for Statistical Computing\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n> q()"},{"path":"r-basics.html","id":"download-r-studio","chapter":"2 R Basics","heading":"2.1.1 Download R studio","text":"Well, need everything command terminal. R community also fully fledged development environment called R Studio free use user friendly work R. can download R studio .tutorial help understand basic overview components R studio.","code":""},{"path":"r-basics.html","id":"r-packages","chapter":"2 R Basics","heading":"2.2 R Packages","text":"R simply statistically programming language, R packages developed R community one key reason robustness, reproducibility flexibility. Many statistics programmers developed 100s packages can run even complex statistics functions single line code.","code":""},{"path":"r-basics.html","id":"r-console","chapter":"2 R Basics","heading":"2.3 R Console","text":"","code":""},{"path":"r-basics.html","id":"getting-help","chapter":"2 R Basics","heading":"2.4 Getting Help","text":"useful syntax ask help","code":"{Get help for an object, in this case for the –-plot– function. \n?plot  #You can also type: help(plot)\n\n#Search the help pages for anything that has the word \"regression\". \n??regression #You can also type:  help.search(\"regression\")\n\n#Search the word \"age\" in the objects available in the current R session.\n apropos(\"age\")\nhelp(package=car) # View documentation in package ‘car’. You can also type: library(help=\"car“)\nhelp(DataABC) # Access codebook for a dataset called ‘DataABC’ in the package ABC\nargs(log) # Description of the command.}"},{"path":"r-basics.html","id":"r-community-and-resources","chapter":"2 R Basics","heading":"2.5 R Community and Resources","text":"R huge community developers supporters. Following resources may useful move ahead research experiments.","code":""},{"path":"r-basics.html","id":"documentation-websites","chapter":"2 R Basics","heading":"2.5.1 Documentation / Websites","text":"","code":""},{"path":"r-basics.html","id":"books","chapter":"2 R Basics","heading":"2.5.2 Books","text":"","code":""},{"path":"r-basics.html","id":"website","chapter":"2 R Basics","heading":"2.5.3 Website","text":"","code":""},{"path":"r-basics.html","id":"cheatsheet","chapter":"2 R Basics","heading":"2.5.4 Cheatsheet","text":"","code":""},{"path":"loading-data-in-r.html","id":"loading-data-in-r","chapter":"3 Loading Data in R","heading":"3 Loading Data in R","text":"Data set can directly imported can entered manually directly R ans save R data file also. Lets see can manually enter save import different data formats R Studio.","code":""},{"path":"loading-data-in-r.html","id":"entering-data-in-r","chapter":"3 Loading Data in R","heading":"3.1 Entering Data in R","text":"can start working R right away entering data R. enter numerical data manually, c (stands ‘column’) command used.Similarly, categorical data can also entered using quotation marks.","code":"  age <- c(45, 23, 36, 29)\n    gpa <- c(\"A+\", \"A\", \"B+\", \"B\")\n  "},{"path":"loading-data-in-r.html","id":"importing-csv-file","chapter":"3 Loading Data in R","heading":"3.2 Importing CSV file","text":"read command function R used read data files. read CSV file, can simply move CSV file working directory load file using read.csv command. need readr package read CSV file., csv1 name assigned CSV file R environment. using variable name whenever want work csv file imported.","code":"'''library (readr)\n  csv1 <- read.csv(\"records.csv\")\n  \n  #To view the structure\n  str(csv1)\n  \n  #To view the CSV file\n  csv1\n  '''"},{"path":"loading-data-in-r.html","id":"importing-spss-and-stata-file","chapter":"3 Loading Data in R","heading":"3.3 Importing SPSS and STATA file","text":"R also package called ‘haven’ helps us read SPSS STATA data files easily R. installing haven package, use read_sav command import SPSS file.Note: seems like using \\ instead  writing path name prevent error : Error: '\\U' used without hex digits character string starting \"'C:\\U\"1","code":"  #Install package\n  install.packages('haven')\n  \n  #Load the package and read SPSS data file\n  \n  library(haven)\n  savdata1 <- read_sav('C:\\\\Users\\\\para\\\\Downloads\\\\ancova.sav')\n  \n  #To verify the file has been imported successfully.\n  savdata1\n  \n  #Load the package and read STATA data file\n  \n  library(haven)\n  dtadata1 <- read_dta('C:\\\\Users\\\\para\\\\Downloads\\\\ancovastata.dta')\n  \n  #To verify the file has been imported successfully.\n  dtadata1\n  "},{"path":"loading-data-in-r.html","id":"importing-excel-file","chapter":"3 Loading Data in R","heading":"3.4 Importing Excel File","text":"readxl package used read excel file R environment.R comprehensive packages import multiple statistical systems. packages include foreign, readdta1 etc. Find Data Import Export R .","code":" #Install package\n  install.packages('readxl')\n  \n  #Load the package and read data\n  \n  library(readxl)\n  xlsdata1 <- read_excel('C:\\\\Users\\\\para\\\\Downloads\\\\ancova.xls')\n  \n  #To verify the file has been imported successfully.\n  xlsdata1\n  "},{"path":"data-representation.html","id":"data-representation","chapter":"4 Data Representation","heading":"4 Data Representation","text":"## Frequency Tables: frequency table displays number occurrences (frequencies) category value data set. particularly useful summarizing categorical data discrete numerical data.","code":"\n# Example data\ndata <- c(\"A\", \"A\", \"B\", \"A\", \"B\", \"C\", \"C\", \"A\", \"B\", \"C\")\n\n# Frequency table\ntable(data)\n#> data\n#> A B C \n#> 4 3 3"},{"path":"data-representation.html","id":"histograms","chapter":"4 Data Representation","heading":"4.1 Histograms:","text":"Histograms used visualize distribution continuous discrete numerical data. display data using intervals (bins) along x-axis frequency observations within bin y-axis.","code":"\n# Example data\ndata_numeric <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n# Histogram\nhist(data_numeric)"},{"path":"data-representation.html","id":"bar-graphs","chapter":"4 Data Representation","heading":"4.2 Bar Graphs:","text":"Bar graphs used displaying categorical data. category represented bar, height (length) bar indicates frequency count category.","code":"\n#Bar graph\nbarplot(table(data))"},{"path":"data-representation.html","id":"pie-charts","chapter":"4 Data Representation","heading":"4.3 Pie Charts:","text":"Pie charts represent categorical data slices circle. size slice proportional frequency category. Pie charts useful visualizing relative proportions categories.","code":"\n#Pie chart\npie(table(data))"},{"path":"data-representation.html","id":"box-plots","chapter":"4 Data Representation","heading":"4.4 Box Plots:","text":"Box plots used visualizing distribution continuous discrete numerical data. show median, quartiles, outliers data, providing compact informative representation data distribution.data representation techniques serves different purpose suited different types data. understanding use method, can effectively communicate data insights findings.","code":"\nboxplot(data_numeric)"},{"path":"describing-data-in-r.html","id":"describing-data-in-r","chapter":"5 Describing Data in R","heading":"5 Describing Data in R","text":"","code":""},{"path":"describing-data-in-r.html","id":"central-tendency","chapter":"5 Describing Data in R","heading":"5.1 Central Tendency:","text":"Central tendency measures provide single value represents center “typical” value dataset. primary measures central tendency mean, median, mode.","code":""},{"path":"describing-data-in-r.html","id":"mean","chapter":"5 Describing Data in R","heading":"5.1.1 Mean","text":"mean, often referred average, sum data points divided total number data points. mean sensitive extreme values (outliers) may always represent true center data.","code":""},{"path":"describing-data-in-r.html","id":"median","chapter":"5 Describing Data in R","heading":"5.1.2 Median","text":"median middle value dataset sorted ascending descending order. dataset odd number data points, median middle value; even number data points, median average two middle values. median less sensitive extreme values compared mean.","code":""},{"path":"describing-data-in-r.html","id":"mode","chapter":"5 Describing Data in R","heading":"5.1.3 Mode","text":"mode value occurs frequently dataset. dataset can one mode (multimodal) mode (value occurs ). mode can used numerical categorical data.calculate measures using “psych” package R, follow steps:Install load “psych” package:calculate mean, median mode.“psych” package provides “describe()” function, calculates various summary statistics, including mode. mean median functions available base R package, can use without loading “psych” package.","code":"\ninstall.packages(\"psych\")\nlibrary(psych)\n# Example data\ndata <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n# Mean\nmean(data)\n#> [1] 5\n\n# Median\nmedian(data)\n#> [1] 5\n\n# Mode\npsych::describe(data)$mode\n#> NULL"},{"path":"describing-data-in-r.html","id":"measures-of-dispersion","chapter":"5 Describing Data in R","heading":"5.2 Measures of Dispersion","text":"primary measures dispersion :","code":""},{"path":"describing-data-in-r.html","id":"range","chapter":"5 Describing Data in R","heading":"5.2.1 Range:","text":"range difference maximum minimum values dataset. gives basic idea spread data sensitive outliers provide information distribution’s shape.\nFormula: Range = Max(X) - Min(X)","code":""},{"path":"describing-data-in-r.html","id":"interquartile-range-iqr","chapter":"5 Describing Data in R","heading":"5.2.2 Interquartile Range (IQR):","text":"IQR difference first quartile (Q1, 25th percentile) third quartile (Q3, 75th percentile) dataset. describes spread middle 50% data less sensitive outliers range.\nFormula: IQR = Q3 - Q1","code":""},{"path":"describing-data-in-r.html","id":"variance","chapter":"5 Describing Data in R","heading":"5.2.3 Variance:","text":"variance average squared differences data point mean. measures degree data points deviate mean. variance influenced outliers expressed squared units.\nFormula (population variance): σ² = Σ(X - μ)² / N\nFormula (sample variance): s² = Σ(X - x̄)² / (n - 1)","code":""},{"path":"describing-data-in-r.html","id":"standard-deviation","chapter":"5 Describing Data in R","heading":"5.2.4 Standard Deviation:","text":"standard deviation square root variance. measures average deviation data points mean expressed units data. Like variance, sensitive outliers.\nFormula (population standard deviation): σ = √σ²\nFormula (sample standard deviation): s = √s²","code":""},{"path":"describing-data-in-r.html","id":"calculating-measures-of-dispersion-using-r","chapter":"5 Describing Data in R","heading":"5.2.5 Calculating Measures of Dispersion Using R","text":"can use psych pakcage calculate measures dispersion.","code":"\n# Example data\ndata <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n# Range\nmax(data) - min(data)\n#> [1] 8\n\n# IQR\nIQR(data)\n#> [1] 4\n\n# Variance\nvar(data)\n#> [1] 7.5\n\n# Standard deviation\nsd(data)\n#> [1] 2.738613"},{"path":"normal-distribution.html","id":"normal-distribution","chapter":"6 Normal Distribution","heading":"6 Normal Distribution","text":"Normal distribution continuous, symmetric, bell-shaped\ndistribution defined two parameters: mean (μ) \nstandard deviation (σ).mean (μ) determines center distribution, standard\ndeviation (σ) controls spread dispersion data.\nApproximately 68% data falls within one standard deviation \nmean, 95% falls within two standard deviations, 99.7% falls\nwithin three standard deviations. known Empirical Rule \n68-95-99.7 rule.probability density function (PDF) Normal distribution \ngiven :f(x) = (1 / (σ * √(2π))) * e^(-1/2 * ((x - μ) / σ)^2):f(x) probability density point x μ mean \ndistribution σ standard deviation distribution e \nbase natural logarithm (approximately 2.718) π \nmathematical constant Pi (approximately 3.141) help visualize \nNormal distribution, consider following example using R:R code generates plot Normal distribution mean 0\nstandard deviation 1, also known standard\nNormal distribution Z-distribution. plot shows \nbell-shaped curve distribution, illustrating data \nsymmetric around mean decreases move away \ncenter.ggplot2 powerful package draw graphics. implements \ngrammar graphics (hence name). can find official\ndocumentation ggplot2 : https://ggplot2.tidyverse.org can\nalso use ggplot2 create different descriptive graphs create\nearlier also customize want.Understanding Normal distribution crucial statistics \nmany statistical tests procedures based assumption \nNormality. also essential , practice, many naturally\noccurring phenomena approximately follow Normal distribution.","code":"\n# Load required libraries\nlibrary(ggplot2)\n\n# Define the mean and standard deviation\nmean <- 0\nsd <- 1\n\n# Generate a sequence of x values\nx <- seq(-4, 4, length.out = 1000)\n\n# Calculate the probability density function for the x values\npdf <- dnorm(x, mean = mean, sd = sd)\n\n# Create the plot\nggplot() +\n  geom_line(aes(x, pdf), color = \"blue\") +\n  xlab(\"X\") +\n  ylab(\"Probability Density\") +\n  ggtitle(\"Normal Distribution (μ = 0, σ = 1)\") +\n  theme_minimal()"},{"path":"skewness-and-kurtosis.html","id":"skewness-and-kurtosis","chapter":"7 Skewness and Kurtosis","heading":"7 Skewness and Kurtosis","text":"Skewness Kurtosis two different measures shapes \ndistribution dataset qualitative methods.","code":""},{"path":"skewness-and-kurtosis.html","id":"skewness","chapter":"7 Skewness and Kurtosis","heading":"7.1 Skewness","text":"Skewness measure asymmetry distribution. describes\ndegree distribution deviates symmetric shape. \nskewness value 0 indicates perfectly symmetric distribution.\nPositive skewness indicates distribution longer tail \nright side, negative skewness indicates longer tail left\nside.","code":""},{"path":"skewness-and-kurtosis.html","id":"kurtosis","chapter":"7 Skewness and Kurtosis","heading":"7.2 Kurtosis","text":"Kurtosis measure “tailedness” “peakedness” \ndistribution. describes distribution’s tails peak compare\nnormal distribution. kurtosis value 0 indicates distribution\nsimilar shape normal distribution. Positive kurtosis\nindicates distribution heavier tails peaked shape \nnormal distribution, negative kurtosis indicates lighter tails\nless peaked shape.","code":""},{"path":"skewness-and-kurtosis.html","id":"generating-skewness-and-kurtosis-using-r","chapter":"7 Skewness and Kurtosis","heading":"7.3 Generating Skewness and Kurtosis using R","text":"can use psych package generate skewness Kurtosis.","code":""},{"path":"standard-scores.html","id":"standard-scores","chapter":"8 Standard Scores","heading":"8 Standard Scores","text":"Standard scores type transformed scores express individual data points dataset relative mean standard deviation dataset. Standard scores allow comparing scores across different distributions scales placing common scale. provide standardized measure position data point within distribution, taking account average value (mean) spread (standard deviation) data.","code":""},{"path":"standard-scores.html","id":"z--score","chapter":"8 Standard Scores","heading":"8.1 Z- Score","text":"z-score type standard score calculated subtracting mean (μ) individual data point (X) dividing result standard deviation (σ):z = (X - μ) / σA z-score represents many standard deviations data point mean. positive z-score indicates data point mean, negative z-score indicates mean. z-score 0 corresponds mean distribution.educational settings, z-scores can used various ways, :Comparing student performance: Z-scores enable comparison student scores across different tests grading scales standardizing scores. allows educators make informed decisions student performance identify students might need additional support resources.Identifying outliers: Z-scores can help identify students perform exceptionally well poorly compared group mean. Outliers can provide insights effectiveness teaching methods, identify areas improvement, recognize exceptional talent.Normalizing grades: cases distribution grades skewed, converting raw scores z-scores can provide equitable assessment student performance. Z-scores can converted percentiles, represent percentage students scored lower particular student, providing standardized ranking within group.calculate z-scores R, can use following code:understanding utilizing z-scores education, educators researchers can make informed decisions student performance, compare results across different assessments, identify patterns trends student achievement.","code":"\n# Example data\ndata <- c(60, 65, 70, 75, 80, 85, 90)\n\n# Calculate the mean and standard deviation\nmean_data <- mean(data)\nsd_data <- sd(data)\n\n# Calculate z-scores\nz_scores <- (data - mean_data) / sd_data\n\nz_scores\n#> [1] -1.3887301 -0.9258201 -0.4629100  0.0000000  0.4629100\n#> [6]  0.9258201  1.3887301"},{"path":"standard-scores.html","id":"t--scores","chapter":"8 Standard Scores","heading":"8.2 T- Scores","text":"T-score type standard score used transform standardize individual data points dataset. T-scores similar z-scores, use different scaling factor place scores specific scale. T-scores especially helpful comparing scores across different distributions scales.T-score calculated subtracting mean (μ) individual data point (X), dividing result standard deviation (σ), multiplying result scaling factor (usually 10) adding constant (usually 50):T = ((X - μ) / σ) * 10 + 50The scaling factor 10 constant 50 ensure T-scores mean 50 standard deviation 10. T-score transformation preserves shape original distribution relative positions data points.T-scores can used various ways:Comparing scores across different tests scales: T-scores enable comparison scores different tests grading scales standardizing scores common scale. allows meaningful comparisons helps decision-making considering different assessments.Norm-referenced interpretation: T-scores often used standardized testing provide norm-referenced interpretation test scores. enables comparison individual’s performance performance reference group (e.g., age grade peers).Clinical psychological assessments: T-scores commonly used clinical psychological assessments interpret scores various tests questionnaires, allowing practitioners compare individual’s performance symptoms normative sample.calculate T-scores R, can use following code:understanding utilizing T-scores, can make informed decisions individual performance, compare results across different assessments, identify patterns trends standardized manner.","code":"\n# Example data\ndata <- c(60, 65, 70, 75, 80, 85, 90)\n\n# Calculate the mean and standard deviation\nmean_data <- mean(data)\nsd_data <- sd(data)\n\n# Calculate T-scores\nt_scores <- ((data - mean_data) / sd_data) * 10 + 50"},{"path":"probability-and-inference.html","id":"probability-and-inference","chapter":"9 Probability and Inference","heading":"9 Probability and Inference","text":"","code":""},{"path":"probability-and-inference.html","id":"probability","chapter":"9 Probability and Inference","heading":"9.1 Probability:","text":"Probability numerical measure likelihood particular event occur. ranges 0 1, 0 meaning event impossible 1 meaning event certain. Probabilities can represented graphically using bar plots pie charts.","code":""},{"path":"probability-and-inference.html","id":"sample-space","chapter":"9 Probability and Inference","heading":"9.2 Sample Space:","text":"sample space set possible outcomes given experiment event. example, coin toss experiment, sample space {Heads, Tails}. sample space can represented using Venn diagrams tree diagrams.","code":""},{"path":"probability-and-inference.html","id":"conditional-probability","chapter":"9 Probability and Inference","heading":"9.3 Conditional Probability:","text":"Conditional probability refers probability event occurring given another event already occurred. can represented graphically using Venn diagrams, show intersections events.","code":""},{"path":"probability-and-inference.html","id":"independence","chapter":"9 Probability and Inference","heading":"9.4 Independence:","text":"Two events independent occurrence one event affect probability event. Graphically, independence can visualized using Venn diagrams probability tables, probability intersection two events equal product individual probabilities.","code":""},{"path":"probability-and-inference.html","id":"bayes-theorem","chapter":"9 Probability and Inference","heading":"9.5 Bayes’ Theorem:","text":"Bayes’ theorem powerful tool updating probability event based new evidence. can visualized using tree diagrams probability tables, show updated probabilities taking account new evidence.","code":""},{"path":"probability-and-inference.html","id":"discrete-and-continuous-probability-distributions","chapter":"9 Probability and Inference","heading":"9.6 Discrete and Continuous Probability Distributions:","text":"Discrete probability distributions describe probabilities outcomes discrete random variables (e.g., number heads coin tosses), continuous probability distributions describe probabilities outcomes continuous random variables (e.g., height individuals). Discrete distributions can visualized using bar plots, continuous distributions can visualized using probability density functions cumulative distribution functions.#Sampling distributionA sampling distribution probability distribution sample statistic (e.g., sample mean, sample proportion) obtained population. helps understand variability sample statistic likelihood obtaining different sample statistics population.","code":""},{"path":"probability-and-inference.html","id":"central-limit-theorem","chapter":"9 Probability and Inference","heading":"9.7 Central Limit Theorem","text":"CLT states , large enough sample size (usually n ≥ 30), distribution sample means approaches normal distribution, regardless shape population distribution. mean sampling distribution equal population mean (μ), standard deviation (standard error) equal population standard deviation (σ) divided square root sample size (n).","code":"\n# Load required libraries\nlibrary(ggplot2)\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Define population parameters\npopulation_mean <- 10\npopulation_sd <- 5\n\n# Define sample size and number of samples\nsample_size <- 50\nnum_samples <- 1000\n\n# Generate random samples and calculate sample means\nsample_means <- replicate(num_samples, mean(rnorm(sample_size, mean = population_mean, sd = population_sd)))\n\n# Plot the distribution of sample means\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"lightblue\", color = \"black\") +\n  geom_density(color = \"blue\") +\n  ggtitle(\"Sampling Distribution of the Mean\") +\n  xlab(\"Sample Means\") +\n  ylab(\"Density\") +\n  theme_minimal()\n#> Warning: The dot-dot notation (`..density..`) was deprecated in\n#> ggplot2 3.4.0.\n#> ℹ Please use `after_stat(density)` instead."},{"path":"probability-and-inference.html","id":"confidence-intervals","chapter":"9 Probability and Inference","heading":"9.8 Confidence Intervals","text":"Confidence intervals range values within true population parameter likely fall, specified level confidence (e.g., 95%). Confidence intervals provide estimate precision uncertainty sample statistic.","code":"\n# Define the sample data\nsample_data <- c(12, 15, 18, 20, 22, 24, 25, 28, 30, 32)\n\n# Calculate the sample mean and standard deviation\nsample_mean <- mean(sample_data)\nsample_sd <- sd(sample_data)\n\n# Calculate the standard error\nstandard_error <- sample_sd / sqrt(length(sample_data))\n\n# Calculate the 95% confidence interval\nalpha <- 0.05\ncritical_value <- qnorm(1 - alpha / 2)\nmargin_of_error <- critical_value * standard_error\nconfidence_interval <- c(sample_mean - margin_of_error, sample_mean + margin_of_error)"},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"10 Hypothesis Testing","heading":"10 Hypothesis Testing","text":"Hypothesis testing method used make decisions population parameters based sample data.","code":""},{"path":"hypothesis-testing.html","id":"hypothesis","chapter":"10 Hypothesis Testing","heading":"10.1 Hypothesis","text":"hypothesis educated guess statement relationship variables characteristics population. hypothesis testing, two main hypotheses:","code":""},{"path":"hypothesis-testing.html","id":"null-hypothesis-h0","chapter":"10 Hypothesis Testing","heading":"10.1.1 Null hypothesis (H0):","text":"hypothesis states effect relationship variables. typically hypothesis researcher wants disprove.","code":""},{"path":"hypothesis-testing.html","id":"alternative-hypothesis-h1","chapter":"10 Hypothesis Testing","heading":"10.1.2 Alternative hypothesis (H1):","text":"hypothesis states effect relationship variables. hypothesis researcher wants prove provide evidence .","code":""},{"path":"hypothesis-testing.html","id":"decision-type-error","chapter":"10 Hypothesis Testing","heading":"10.2 Decision Type Error","text":"performing hypothesis testing, two types decision errors:Type Error (α): error occurs null hypothesis rejected actually true. words, ’s false positive. probability committing Type error denoted significance level (α), typically set 0.05 0.01.\nType II Error (β): error occurs null hypothesis rejected actually false. words, ’s false negative. probability committing Type II error denoted β. power test (1 - β) measures ability test detect effect truly exists.\ngraphical representation types decision errors:Hypothesis Testing ErrorsThis table represents different outcomes making decisions based hypothesis testing. columns represent reality (.e., whether null hypothesis true false), rows represent decision made based hypothesis test (.e., whether reject reject null hypothesis). cells show types decision errors (Type Type II errors) correct decisions.","code":"|                  | Null Hypothesis (H0) is True | Null Hypothesis (H0) is False |\n|------------------|------------------------------|-------------------------------|\n| Reject H0        | Type I Error (α)             | Correct Decision (1 - β)      |\n| Fail to Reject H0| Correct Decision (1 - α)     | Type II Error (β)             |"},{"path":"hypothesis-testing.html","id":"level-of-signficance","chapter":"10 Hypothesis Testing","heading":"10.3 Level of Signficance","text":"level significance critical component hypothesis testing sets threshold determining whether observed effect statistically significant .level significance denoted Greek letter α (alpha) represents probability making Type error. Type error occurs reject null hypothesis (H0) actually true. choosing level significance, researchers define risk willing take rejecting true null hypothesis. Common levels significance 0.05 (5%) 0.01 (1%).better understand role level significance hypothesis testing, let’s consider following steps:Formulate null hypothesis (H0) alternative hypothesis (H1): null hypothesis typically states effect relationship variables, alternative hypothesis states effect relationship.Choose level significance (α): Determine threshold probability making Type error. example, α set 0.05, 5% chance rejecting true null hypothesis.Perform statistical test calculate test statistic: test statistic calculated using sample data, helps determine far observed sample mean hypothesized population mean. case single mean, one-sample t-test commonly used, test statistic t-value.Determine critical value p-value: Compare calculated test statistic critical value p-value (probability value) make decision null hypothesis. critical value threshold value depends chosen level significance distribution test statistic. p-value represents probability obtaining test statistic extreme extreme observed test statistic assumption null hypothesis true.Make decision: test statistic extreme critical value, p-value less level significance (α), reject null hypothesis. Otherwise, fail reject null hypothesis.","code":""},{"path":"hypothesis-testing.html","id":"t-statistic","chapter":"10 Hypothesis Testing","heading":"10.4 T-statistic","text":"t-statistic standardized measure used hypothesis testing compare observed sample mean hypothesized population mean. takes account sample mean, hypothesized population mean, standard error mean. Mathematically, t-statistic can calculated using following formula:t = (X̄ - μ) / (s / √n):t t-statistic\nX̄ sample mean\nμ hypothesized population mean\ns sample standard deviation\nn sample size","code":""},{"path":"hypothesis-testing.html","id":"t-distribution","chapter":"10 Hypothesis Testing","heading":"10.4.1 T-distribution","text":"t-distribution, also known Student’s t-distribution, probability distribution used population standard deviation unknown sample size small. similar normal distribution thicker tails, accounts increased variability due using sample standard deviation estimate population standard deviation. shape t-distribution depends degrees freedom (df), related sample size (df = n - 1). sample size increases, t-distribution approaches normal distribution.calculate t-statistic R, can use following code:perform one-sample t-test R, calculates t-statistic p-value automatically, can use t.test() function:","code":"\n# Sample data\ndata <- c(12, 14, 16, 18, 20)\n\n# Hypothesized population mean\nhypothesized_mean <- 15\n\n# Calculate the sample mean, standard deviation, and size\nsample_mean <- mean(data)\nsample_sd <- sd(data)\nsample_size <- length(data)\n\n# Calculate the t-statistic\nt_statistic <- (sample_mean - hypothesized_mean) / (sample_sd / sqrt(sample_size))\n\n# Print the t-statistic\nprint(t_statistic)\n#> [1] 0.7071068\n# Perform a one-sample t-test\nt_test_result <- t.test(data, mu = hypothesized_mean)\n\n# Print the t-test result\nprint(t_test_result)\n#> \n#>  One Sample t-test\n#> \n#> data:  data\n#> t = 0.70711, df = 4, p-value = 0.5185\n#> alternative hypothesis: true mean is not equal to 15\n#> 95 percent confidence interval:\n#>  12.07351 19.92649\n#> sample estimates:\n#> mean of x \n#>        16"},{"path":"hypothesis-testing.html","id":"intepreting-normality-evidence","chapter":"10 Hypothesis Testing","heading":"10.4.2 Intepreting Normality Evidence","text":"using t-test, assumption normality important. data follow normal distribution ensure validity test results. assess normality data, can use visual methods (histograms, Q-Q plots) statistical tests (e.g., Shapiro-Wilk test).important t-test assumes data follow normal distribution, verifying assumption helps ensure validity test results.generate normality evidence performing t-test, can use following methods:Visual methods: Histograms Q-Q plots can provide visual assessment normality data.Statistical tests: Shapiro-Wilk test Kolmogorov-Smirnov test commonly used test normality. tests generate p-values, can compared chosen significance level (e.g., 0.05) determine data deviate significantly normality.R, can create histogram Q-Q plot using following code:Create histogram Q-Q plot:Perform Shapiro-Wilk test:interpret normality evidence, follow guidelines:Visual methods: Inspect histogram Q-Q plot. histogram roughly bell-shaped points Q-Q plot fall approximately reference line, data can considered approximately normally distributed.Statistical tests: Check p-values normality tests. p-value greater chosen significance level (e.g., 0.05), null hypothesis (.e., data follow normal distribution) rejected. suggests data deviate significantly normality.Keep mind single method foolproof, ’s often good idea use combination visual statistical methods assess normality. data appear non-normal, might consider using non-parametric alternatives t-test transforming data achieve normality.","code":"\n# Load required libraries\nlibrary(ggplot2)\n\n# Sample data\ndata <- c(12, 14, 16, 18, 20)\n\n# Create a histogram\nggplot(data.frame(data), aes(data)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"white\") +\n  theme_minimal()\n\n# Create a Q-Q plot\nqqnorm(data)\nqqline(data, col = \"red\")\n# Perform the Shapiro-Wilk test\nshapiro_test_result <- shapiro.test(data)\n\n# Print the test result\nprint(shapiro_test_result)\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  data\n#> W = 0.98676, p-value = 0.9672"},{"path":"hypothesis-testing.html","id":"statistical-power","chapter":"10 Hypothesis Testing","heading":"10.5 Statistical Power","text":"Statistical power probability correctly rejecting null hypothesis false, means committing Type II error. Power influenced factors sample size, effect size, chosen significance level (α). Power analysis helps researchers determine appropriate sample size needed achieve desired level power, typically 0.8 higher.perform power analysis R, can use pwr package, provides set functions power calculations various statistical tests, including t-test.’s step--step procedure generating testing power using R:Install load pwr package:Define parameters power analysis. need specify effect size (Cohen’s d), sample size, significance level (α):Use pwr.t.test() function calculate power one-sample t-test:output show calculated power, sample size, effect size, significance level. power desired level (e.g., 0.8), can adjust sample size effect size recalculate power determine necessary changes achieving desired power level.’s essential consider practical implications effect size sample size planning study. large effect size may easier detect might occur frequently real-world situations. Conversely, small effect size might difficult detect may require larger sample size achieve adequate power.","code":"\n\n# Load the pwr package\nlibrary(pwr)\n#> Warning: package 'pwr' was built under R version 4.2.3\n# Define parameters for power analysis\neffect_size <- 0.8  # Cohen's d\nsample_size <- 20\nsignificance_level <- 0.05\n# Calculate the power for a one-sample t-test\npower_result <- pwr.t.test(n = 500,\n                           d = effect_size,\n                           sig.level = significance_level,\n                           type = \"one.sample\",\n                           alternative = \"two.sided\")\n\n# Print the power result\nprint(power_result)\n#> \n#>      One-sample t test power calculation \n#> \n#>               n = 500\n#>               d = 0.8\n#>       sig.level = 0.05\n#>           power = 1\n#>     alternative = two.sided"},{"path":"independent-samples-t---test.html","id":"independent-samples-t---test","chapter":"11 Independent Samples T - Test","heading":"11 Independent Samples T - Test","text":"table provides comprehensive comparison dependent independent samples, including definitions, examples, hypothesis testing, assumptions, statistical tests, effect size measures, R functions. understanding differences, can choose appropriate statistical test data interpret results correctly.","code":""},{"path":"independent-samples-t---test.html","id":"independent-samples-t-test","chapter":"11 Independent Samples T - Test","heading":"11.1 Independent Samples t-test","text":"independent samples t-test used compare means two independent groups determine significant difference .independent samples t-test based following null (H₀) alternative (H₁) hypotheses:H₀: μ₁ = μ₂ (significant difference means two groups.)\nH₁: μ₁ ≠ μ₂ (significant difference means two groups.)\ntest statistic independent samples t-test t-value, calculated using following formula:t = (M₁ - M₂) / sqrt((s₁²/n₁) + (s₂²/n₂)):M₁ M₂ means two groups\ns₁² s₂² variances two groups\nn₁ n₂ sample sizes two groups\nt-value follows t-distribution degrees freedom (df) approximated following formula:df = min(n₁ - 1, n₂ - 1)t-value degrees freedom calculated, p-value can determined comparing t-value t-distribution appropriate degrees freedom. p-value less chosen significance level (e.g., 0.05), null hypothesis can rejected, indicating significant difference means two groups.","code":""},{"path":"independent-samples-t---test.html","id":"independent-t-test-using-r","chapter":"11 Independent Samples T - Test","heading":"11.1.1 Independent t-test using R","text":"need data two independent groups, typically stored data frame one variable representing group membership another variable representing outcome interest.Perform independent samples t-test: Use t.test() function R, specifying formula data frame arguments.output t.test() function include t-value, degrees freedom, p-value, confidence interval difference means. p-value less chosen significance level (e.g., 0.05), can reject null hypothesis, concluding significant difference means two groups.","code":"\n# Example data\ngroup <- c(\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"B\")\noutcome <- c(10, 12, 14, 16, 18, 20, 22, 24, 26, 28)\n\n# Create a data frame\ndata <- data.frame(group, outcome)\n# Perform the independent samples t-test\nt_test_result <- t.test(outcome ~ group, data = data)\n\n# Print the test result\nprint(t_test_result)\n#> \n#>  Welch Two Sample t-test\n#> \n#> data:  outcome by group\n#> t = -5, df = 8, p-value = 0.001053\n#> alternative hypothesis: true difference in means between group A and group B is not equal to 0\n#> 95 percent confidence interval:\n#>  -14.612008  -5.387992\n#> sample estimates:\n#> mean in group A mean in group B \n#>              14              24"},{"path":"paired-t-test.html","id":"paired-t-test","chapter":"12 Paired t-test","heading":"12 Paired t-test","text":"paired samples t-test used observations collected individuals matched pairs (e.g., siblings, twins) different conditions different time points. purpose test determine significant difference means paired differences.paired t-test based following null (H₀) alternative (H₁) hypotheses:H₀: μ_d = 0 (significant difference means paired differences.)H₀: μ_d = 0 (significant difference means paired differences.)H₁: μ_d ≠ 0 (significant difference means paired differences.)H₁: μ_d ≠ 0 (significant difference means paired differences.)Mathematically, test statistic paired t-test (t-value) calculated using following formula:t = (M_d - μ_d) / (s_d / sqrt(n)):M_d mean paired differencesM_d mean paired differencesμ_d population mean difference (0 null hypothesis)μ_d population mean difference (0 null hypothesis)s_d standard deviation paired differencess_d standard deviation paired differencesn number pairsn number pairsThe t-value follows t-distribution degrees freedom (df) equal n - 1.t-value follows t-distribution degrees freedom (df) equal n - 1.paired t-test used observations within pair related matched (e.g., pre-test post-test scores individuals, scores matched pairs like siblings twins).test compares means paired differences rather means original observations.Examples:Comparing pre-test post-test scores students determine effectiveness teaching intervention.Comparing pre-test post-test scores students determine effectiveness teaching intervention.Comparing performance students two different courses taught instructor.Comparing performance students two different courses taught instructor.Recommendations:Use paired t-test dependent samples interested difference means paired differences.Use paired t-test dependent samples interested difference means paired differences.Ensure assumptions paired t-test met (see ).Ensure assumptions paired t-test met (see ).Sample size:sample size large enough provide adequate statistical power detect meaningful effect.sample size large enough provide adequate statistical power detect meaningful effect.required sample size depends effect size, significance level, desired power. can calculated using power analysis techniques (e.g., using pwr package R).required sample size depends effect size, significance level, desired power. can calculated using power analysis techniques (e.g., using pwr package R).Assumptions:Paired observations: observations within pair related matched, pre-test post-test scores individual, scores matched pairs like siblings twins.Paired observations: observations within pair related matched, pre-test post-test scores individual, scores matched pairs like siblings twins.Random sampling: pairs observations obtained random sampling population interest. ensures sample representative population results can generalized.Random sampling: pairs observations obtained random sampling population interest. ensures sample representative population results can generalized.Normality differences: differences paired observations approximately normally distributed. assumption can checked using variety methods, histograms, Q-Q plots, statistical tests like Shapiro-Wilk test.Normality differences: differences paired observations approximately normally distributed. assumption can checked using variety methods, histograms, Q-Q plots, statistical tests like Shapiro-Wilk test.Independence pairs: pairs observations independent . words, one pair’s difference influence another pair’s difference.Independence pairs: pairs observations independent . words, one pair’s difference influence another pair’s difference.Interval ratio scale data: data paired observations measured interval ratio scale. means data meaningful zero point equal intervals adjacent values.\nessential ensure assumptions met conducting paired t-test, violation assumptions may lead incorrect inferences. assumptions violated, alternative statistical tests data transformation methods might appropriate.Interval ratio scale data: data paired observations measured interval ratio scale. means data meaningful zero point equal intervals adjacent values.essential ensure assumptions met conducting paired t-test, violation assumptions may lead incorrect inferences. assumptions violated, alternative statistical tests data transformation methods might appropriate.","code":""},{"path":"paired-t-test.html","id":"performing-the-paired-t-test-using-r","chapter":"12 Paired t-test","heading":"12.0.1 Performing the paired t-test using R","text":"need data two related groups samples, typically stored data frame two variables representing paired observations. loading requirec libraries. using pysch package.","code":"\nswimdata <- read.csv(\"exampledata/Ch7_swim.csv\")\nsummary(swimdata)\n#>     pretest         posttest    \n#>  Min.   :58.00   Min.   :54.00  \n#>  1st Qu.:61.25   1st Qu.:56.25  \n#>  Median :63.50   Median :59.50  \n#>  Mean   :64.00   Mean   :59.00  \n#>  3rd Qu.:65.75   3rd Qu.:61.75  \n#>  Max.   :72.00   Max.   :64.00"},{"path":"paired-t-test.html","id":"data-screening-procedures","chapter":"12 Paired t-test","heading":"12.0.2 Data screening procedures","text":"performing paired t-test, essential check assumptions mentioned earlier, including normality differences presence outliers.Check outliers using boxplots:Check normality differences using histograms Q-Q plots:can also assess normality using Shapiro-Wilk test.","code":"\nboxplot(swimdata$pretest, swimdata$posttest, names = c(\"Pretest\", \"Posttest\"), ylab = \"Scores\", main = \"Boxplots for Pretest and Posttest\")\n# Compute the differences between paired observations\nswimdata$difference <- swimdata$posttest - swimdata$pretest\n\n# Create a histogram of the differences\nhist(swimdata$difference, main = \"Histogram of Paired Differences\", xlab = \"Difference\", ylab = \"Frequency\")\n\n# Create a Q-Q plot of the differences\nqqnorm(swimdata$difference, main = \"Q-Q Plot of Paired Differences\")\nqqline(swimdata$difference, col = \"red\")\nshapiro.test(swimdata$difference)\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  swimdata$difference\n#> W = 0.95557, p-value = 0.7344"},{"path":"paired-t-test.html","id":"performing-the-paired-t-test","chapter":"12 Paired t-test","heading":"12.0.3 Performing the paired t-test","text":"Paired t-test can performed using t.test() function.output paired t-test includes several pieces information:t-value: calculated t-statistic 7.3193. value represents difference means pretest posttest scores, terms standard deviations.Degrees freedom (df): degrees freedom t-test 9, calculated number pairs minus 1 (n - 1).p-value: p-value 4.472e-05 (0.00004472), probability observing t-value extreme extreme calculated t-value, assuming null hypothesis (significant difference means paired differences) true.Alternative hypothesis: output states alternative hypothesis true mean difference equal 0.95% confidence interval: confidence interval [3.454652, 6.545348], means can 95% confident true population mean difference lies within interval.Sample estimates: mean difference pretest posttest scores 5.Based output, since p-value (0.00004472) less common significance level (0.05), can reject null hypothesis conclude significant difference pretest posttest scores swimdata dataset. positive mean difference (5) indicates , average, posttest scores higher pretest scores. 95% confidence interval suggests true population mean difference lies 3.454652 6.545348.assumptions paired t-test met p-value less chosen significance level, can conclude significant difference means paired differences. Otherwise, assumptions violated, consider alternative statistical tests data transformation methods.","code":"\n# Perform the paired t-test\nt_test_result <- t.test(swimdata$pretest, swimdata$posttest, paired = TRUE)\n\n# Print the test result\nprint(t_test_result)\n#> \n#>  Paired t-test\n#> \n#> data:  swimdata$pretest and swimdata$posttest\n#> t = 7.3193, df = 9, p-value = 4.472e-05\n#> alternative hypothesis: true mean difference is not equal to 0\n#> 95 percent confidence interval:\n#>  3.454652 6.545348\n#> sample estimates:\n#> mean difference \n#>               5"},{"path":"covariance.html","id":"covariance","chapter":"13 Covariance","heading":"13 Covariance","text":"Covariation, covariance, measure two variables change together. values one variable increase values variable increase, covariance positive, indicating positive relationship. values one variable decrease values variable increase, covariance negative, indicating negative relationship. apparent pattern variables, covariance close 0, indicating relationship.Mathematically, covariance two variables X Y, n observations , can calculated using formula:Cov(X, Y) = Σ((Xi - X_mean) * (Yi - Y_mean)) / (n - 1):Xi Yi individual data points X_mean Y_mean means X Y variables, respectively Σ denotes sum data points n number data points scatterplot, covariance can visually inferred direction closeness points. points tightly clustered around positive slope, covariance positive. clustered around negative slope, covariance negative. points scattered randomly clear pattern, covariance close 0.can use R inbuilt cov() function calculate covariance.covariance 4.5 means positive relationship two variables. one variable increases, variable also tends increase. However, important note covariance alone provide information strength relationship, scale covariance depends scales two variables.better understand strength direction relationship two variables, can calculate correlation coefficient (e.g., Pearson’s correlation coefficient), standardized measure association ranges -1 1.","code":"\nlibrary(readr)\n# Read the CSV file into a data frame\ncovdata <- read_csv(\"exampledata/Ch10_kidspets.csv\")\n#> Rows: 5 Columns: 2\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> dbl (2): Children, Pets\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Calculate the covariance between two variables (e.g., var1 and var2)\ncovariance <- cov(covdata$Children, covdata$Pets)\nprint(covariance)\n#> [1] 4.5"},{"path":"scatter-plots.html","id":"scatter-plots","chapter":"14 Scatter Plots","heading":"14 Scatter Plots","text":"","code":""},{"path":"scatter-plots.html","id":"bivariate-measures-of-association","chapter":"14 Scatter Plots","heading":"14.1 Bivariate Measures of Association","text":"Bivariate measures association statistical methods used examine strength, direction, nature relationship two variables. educational research, measures help researchers understand associations different factors may influence educational outcomes, student performance, teaching strategies, resource allocation. understanding relationships, researchers can make informed decisions develop effective interventions improve educational outcomes.","code":""},{"path":"scatter-plots.html","id":"scatterplots","chapter":"14 Scatter Plots","heading":"14.2 Scatterplots","text":"Scatterplots important tool understanding bivariate measures association. scatterplot graphical representation relationship two variables, point plot represents pair observations two variables. pattern points can give us idea direction, strength, shape relationship two variables.example, educational research, scatterplot used visualize relationship students’ reading scores math scores. examining scatterplot, researchers can identify whether positive negative relationship two variables, whether relationship linear nonlinear, strong association .key insights scatterplots can provide:Direction: direction relationship two variables can positive, negative, relationship. positive relationship, one variable increases, variable also increases. negative relationship, one variable increases, variable decreases. relationship, points scattered randomly, indicating association two variables.Strength: strength relationship can determined closely points follow specific pattern (e.g., straight line). strong relationship points closely following pattern, weak relationship points scattered widely around pattern.Shape: shape relationship can linear, nonlinear, relationship. linear relationship follows straight line, nonlinear relationship follows curve non-straight pattern. relationship means points scattered randomly, indicating association two variables.example, lets create five different types plots see differ terms attributes.R code generate 5 different possible scatterplots, representing different type relationship. Lets display individually see show relationship.","code":"\n# Load ggplot2 package\nlibrary(ggplot2)\n\n# Create sample datasets\nset.seed(42)\n\npositive_linear <- data.frame(x = 1:50, y = 1:50 + rnorm(50, sd = 5))\nnegative_linear <- data.frame(x = 1:50, y = 50:1 + rnorm(50, sd = 5))\nnonlinear <- data.frame(x = 1:50, y = (1:50)^2 + rnorm(50, sd = 500))\nno_relationship <- data.frame(x = 1:50, y = rnorm(50))\nclustered <- data.frame(x = c(rnorm(25, mean = 20), rnorm(25, mean = 40)), y = c(rnorm(25, mean = 30), rnorm(25, mean = 50)))\n\n# Function to create scatterplots\ncreate_scatterplot <- function(data, title) {\n  ggplot(data, aes(x = x, y = y)) +\n    geom_point() +\n    xlab(\"X\") +\n    ylab(\"Y\") +\n    ggtitle(title) +\n    theme_minimal()\n}\n\n# Generate scatterplots\npositive_linear_plot <- create_scatterplot(positive_linear, \"Positive Linear Relationship\")\nnegative_linear_plot <- create_scatterplot(negative_linear, \"Negative Linear Relationship\")\nnonlinear_plot <- create_scatterplot(nonlinear, \"Nonlinear Relationship\")\nno_relationship_plot <- create_scatterplot(no_relationship, \"No Relationship\")\nclustered_plot <- create_scatterplot(clustered, \"Clustered Relationship\")"},{"path":"scatter-plots.html","id":"positive-linear-relationship","chapter":"14 Scatter Plots","heading":"14.2.0.1 Positive linear relationship:","text":"points scatterplot show upward trend, indicating positive relationship variables.","code":"\nprint(positive_linear_plot)"},{"path":"scatter-plots.html","id":"negative-linear-relationship","chapter":"14 Scatter Plots","heading":"14.2.0.2 Negative linear relationship","text":"points scatterplot show downward trend, indicating negative relationship variables.","code":"\nprint(negative_linear_plot)"},{"path":"scatter-plots.html","id":"nonlinear-relationship","chapter":"14 Scatter Plots","heading":"14.2.0.3 Nonlinear relationship","text":"points scatterplot follow curve non-straight pattern, indicating nonlinear relationship variables.","code":"\nprint(nonlinear_plot)"},{"path":"scatter-plots.html","id":"no-relationship","chapter":"14 Scatter Plots","heading":"14.2.0.4 No relationship","text":"points scatterplot scattered randomly, indicating association variables.","code":"\nprint(no_relationship_plot)"},{"path":"scatter-plots.html","id":"clustered-relationship","chapter":"14 Scatter Plots","heading":"14.2.0.5 Clustered relationship","text":"points scatterplot form clusters, indicating relationship variables may complex may factors play.scatterplots can help visualize understand associations different variables data.","code":"\nprint(clustered_plot)"},{"path":"scatter-plots.html","id":"generating-scatterplots-using-r","chapter":"14 Scatter Plots","heading":"14.3 Generating Scatterplots using R","text":"First, let’s install load ggplot2 package, create sample dataset:Now, can create scatterplot reading_scores vs. math_scores.example , used ggplot2 package create scatterplot. aes function maps x y axes reading_scores math_scores variables, respectively. geom_point function adds points scatterplot, representing paired observations reading_scores math_scores. xlab, ylab, ggtitle, theme_minimal functions used customize appearance scatterplot.","code":"\n# Load ggplot2 package\nlibrary(ggplot2)\n\n# Create a sample dataset\ndata <- data.frame(\n  reading_scores = c(50, 60, 65, 55, 70, 75, 80, 85, 90, 95),\n  math_scores = c(55, 60, 70, 50, 75, 80, 85, 90, 95, 100)\n)\n# Create a scatterplot\nscatterplot <- ggplot(data, aes(x = reading_scores, y = math_scores)) +\n  geom_point() +\n  xlab(\"Reading Scores\") +\n  ylab(\"Math Scores\") +\n  ggtitle(\"Scatterplot of Reading Scores vs. Math Scores\") +\n  theme_minimal()\n\n# Display the scatterplot\nprint(scatterplot)"},{"path":"correlation.html","id":"correlation","chapter":"15 Correlation","heading":"15 Correlation","text":"Correlation standardized measure linear relationship two variables. Pearson’s correlation coefficient (r), commonly used correlation measure, ranges -1 1, -1 indicating perfect negative relationship, 1 indicating perfect positive relationship, 0 indicating linear relationship.Mathematically, Pearson’s correlation coefficient (r) can calculated using following formula:r = Σ((Xi - X_mean) * (Yi - Y_mean)) / (sqrt(Σ(Xi - X_mean)^2) * sqrt(Σ(Yi - Y_mean)^2)):Xi Yi individual data points variables X Y, respectively X_mean Y_mean means variables X Y, respectively Σ denotes sum data points formula calculates correlation coefficient dividing covariance X Y product standard deviations.interpret result:correlation coefficient close 1 indicates strong positive relationship variables, meaning one variable increases, variable also tends increase.correlation coefficient close -1 indicates strong negative relationship, meaning one variable increases, variable tends decrease.correlation coefficient close 0 suggests linear relationship two variables.significant correlation two variables indicates relationship , necessarily mean one variable causes . Additional research analysis may needed establish causality.","code":"\nlibrary(readr)\n# Read the CSV file into a data frame\ncordata <- read_csv(\"exampledata/Ch10_kidspets.csv\")\n#> Rows: 5 Columns: 2\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> dbl (2): Children, Pets\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Calculate the covariance between two variables (e.g., var1 and var2)\ncorrelation<- cor(cordata$Children, cordata$Pets)\nprint(correlation)\n#> [1] 0.9"},{"path":"simple-linear-regression.html","id":"simple-linear-regression","chapter":"16 Simple Linear Regression","heading":"16 Simple Linear Regression","text":"Simple linear regression statistical method used model \nrelationship single independent variable (predictor) \ndependent variable (outcome). basic technique can help\nresearchers understand association two continuous variables\nmake predictions based observed data.simple linear regression, try find best-fitting straight\nline data points scatterplot. line represents \npredicted value dependent variable (Y) given value \nindependent variable (X). equation line follows:Y = b0 + b1X + εHere:Y dependent variable (outcome) X independent variable\n(predictor) b0 intercept, represents value Y X\nzero b1 slope, represents change Y one-unit\nincrease X ε error term, accounts difference\nactual predicted values Y simple linear\nregression, goal find values b0 b1 minimize\nsum squared differences observed values Y \npredicted values (based line). method called \nleast squares estimation.better understand simple linear regression, let’s consider \nscatterplot two variables X Y:","code":"y\n|\n|       •\n|     •\n|   •\n| •\n+----------------\n  x"},{"path":"simple-linear-regression.html","id":"regression-using-r","chapter":"16 Simple Linear Regression","heading":"16.1 Regression using R","text":"perform simple linear regression R using psych package, can\nuse following code:output summary simple linear regression model fitted \ndata, Success dependent variable (outcome), represents score employment success scale.\nOptimism independent variable (predictor),represents scores work optimism scale.Let’s break piece piece:Residuals: Residuals differences observed \npredicted values dependent variable. summary provides \nminimum, 1st quartile, median, 3rd quartile, maximum residuals. \ninformation helps us understand spread residuals, \nideally evenly distributed close zero.Coefficients: coefficients table provides estimates,\nstandard errors, t-values, p-values intercept predictor\nvariable (Optimism).estimated intercept (b₀) 8.86473, estimated slope (b₁)\nOptimism predictor 0.52496. means linear\nregression equation :Y = 8.86473 + 0.52496 * OptimismThe p-value intercept 0.088358, greater 0.05,\nsuggesting intercept statistically significant \n0.05 level. p-value Optimism predictor 0.000181, \nless 0.001, indicating Optimism statistically significant\n0.001 level.Model fit diagnostics: output provides information \nmodel’s goodness fit diagnostic statistics.","code":"\n# Load required packages\nlibrary(readr)\nlibrary(psych)\n#> Warning: package 'psych' was built under R version 4.2.3\n\n# Read the CSV file into a data frame\ndata_file <- \"exampledata/Empsuccess.csv\"\ndata <- read_csv(data_file)\n#> Rows: 10 Columns: 2\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> dbl (2): Optimism, Success\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Perform simple linear regression\nmodel <- lm(Success ~ Optimism, data = data)\n\n# Display the model summary\nsummary(model)\n#> \n#> Call:\n#> lm(formula = Success ~ Optimism, data = data)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -4.4380 -1.9932  0.1626  2.2568  3.7118 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  8.86473    4.56965   1.940 0.088358 .  \n#> Optimism     0.52496    0.08034   6.535 0.000181 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 3.165 on 8 degrees of freedom\n#> Multiple R-squared:  0.8422, Adjusted R-squared:  0.8225 \n#> F-statistic:  42.7 on 1 and 8 DF,  p-value: 0.0001814"},{"path":"simple-linear-regression.html","id":"scatter-plot","chapter":"16 Simple Linear Regression","heading":"16.2 Scatter Plot","text":"can create scatter plot data add regression line using ggplot2 package:","code":"\n# Load required packages\nlibrary(ggplot2)\n#> \n#> Attaching package: 'ggplot2'\n#> The following objects are masked from 'package:psych':\n#> \n#>     %+%, alpha\n\n# Create a scatterplot with the regression line\nggplot(data, aes(x = Optimism, y = Success)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  xlab(\"Optimism\") +\n  ylab(\"Success\") +\n  ggtitle(\"Simple Linear Regression\") +\n  theme_minimal()\n#> `geom_smooth()` using formula = 'y ~ x'"},{"path":"multiple-regression.html","id":"multiple-regression","chapter":"17 Multiple Regression","heading":"17 Multiple Regression","text":"Multiple linear regression extension simple linear regression, model relationship single dependent (outcome) variable multiple independent (predictor) variables. goal predict dependent variable based values independent variables accounting influence predictor variable.multiple linear regression equation follows:Y = β0 + β1X1 + β2X2 + … + βnXn + εWhere:Y dependent variable\nβ0 intercept (value Y independent variables zero)\nβ1, β2, …, βn regression coefficients independent variable X1, X2, …, Xn\nε error term, representing difference actual predicted values Y\nregression coefficients (β1, β2, …, βn) represent average change dependent variable one-unit increase corresponding independent variable, holding independent variables constant.can perform linear regression R using psych package.output shows us regression coefficients, standard errors, t-values, p-values independent variable. can also see R-squared value, adjusted R-squared value, model fit statistics.summary statistics residuals provided, including minimum, first quartile (1Q), median, third quartile (3Q), maximum values.coefficients table provides regression coefficients (Estimate), standard errors (Std. Error), t-values (t value), p-values (Pr(>|t|)) independent variable, well intercept.regression equation based output :Y = 0.637906 + 0.468670 * UGPA + 0.012463 * GRE_TotalWhere:Y dependent variable\nUGPA first independent variable (Undergraduate GPA)\nGRE_Total second independent variable (Total GRE score)\nSignificance codes: indicate level statistical significance independent variable, 0.001 (*), 0.01 (), 0.05 (.), 0.1 ( ).","code":"\n# Load the necessary libraries.\nlibrary(psych)\n#> Warning: package 'psych' was built under R version 4.2.3\nlibrary(tidyverse)\n#> Warning: package 'tidyverse' was built under R version\n#> 4.2.3\n#> ── Attaching core tidyverse packages ──── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.0     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ ggplot2::%+%()   masks psych::%+%()\n#> ✖ ggplot2::alpha() masks psych::alpha()\n#> ✖ dplyr::filter()  masks stats::filter()\n#> ✖ dplyr::lag()     masks stats::lag()\n#> ℹ Use the \n\n# Reading the CSV file. \ndata <- read_csv(\"exampledata/Ch18_GGPA.csv\")\n#> Rows: 11 Columns: 3\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> dbl (3): GRE_Total, UGPA, GGPA\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Define the model. \nmodel <- lm(GGPA  ~UGPA + GRE_Total, data = data)\n\nsummary(model)\n#> \n#> Call:\n#> lm(formula = GGPA ~ UGPA + GRE_Total, data = data)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -0.19943 -0.06029  0.02812  0.06216  0.17207 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 0.637906   0.326537   1.954 0.086517 .  \n#> UGPA        0.468670   0.093181   5.030 0.001015 ** \n#> GRE_Total   0.012463   0.002288   5.447 0.000611 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.1127 on 8 degrees of freedom\n#> Multiple R-squared:  0.9076, Adjusted R-squared:  0.8845 \n#> F-statistic: 39.29 on 2 and 8 DF,  p-value: 7.289e-05"},{"path":"multiple-regression.html","id":"model-fit-statistics","chapter":"17 Multiple Regression","heading":"17.0.1 Model Fit Statistics:","text":"Residual standard error: standard deviation residuals, indicating average difference actual predicted values dependent variable.Multiple R-squared: value represents proportion total variability dependent variable explained independent variables model.Adjusted R-squared: value adjusts R-squared number independent variables, providing accurate estimate model’s explanatory power multiple predictors included.F-statistic p-value: values indicate overall significance regression model, F-statistic measuring ratio explained variance unexplained variance p-value providing probability observing F-statistic null hypothesis (.e., regression coefficients equal zero).","code":""},{"path":"one-way-anova.html","id":"one-way-anova","chapter":"18 One way ANOVA","heading":"18 One way ANOVA","text":"","code":""},{"path":"tukeys-post-hoc-tests.html","id":"tukeys-post-hoc-tests","chapter":"19 Tukey’s post hoc tests","heading":"19 Tukey’s post hoc tests","text":"","code":""},{"path":"chi-square-tests.html","id":"chi-square-tests","chapter":"20 Chi Square Tests","heading":"20 Chi Square Tests","text":"","code":""},{"path":"chi-square-tests.html","id":"chi-square-goodness-of-fit-test","chapter":"20 Chi Square Tests","heading":"20.1 Chi Square Goodness of Fit Test","text":"","code":""},{"path":"chi-square-tests.html","id":"chi-sqaure-test-of-association","chapter":"20 Chi Square Tests","heading":"20.2 Chi Sqaure test of association","text":"","code":""},{"path":"g-power.html","id":"g-power","chapter":"21 G* Power","heading":"21 G* Power","text":"","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
