[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Welcome Quantitative Methods - R Cookbook. cookbook covers practical worked examples can easily apply dataset also includes discussion recipe working. cover descriptive basic inferential statistics, including graphs, frequency distributions, central tendency, dispersion, probability, hypothesis testing, tests mean differences, correlation simple regression, chi-square tests. cookbook designed facilitate graduate post graduate students develop knowledge understanding various statistical concepts procedures R programming.","code":""},{"path":"index.html","id":"general-objectives","chapter":"Welcome","heading":"General Objectives","text":"course based upon 3 credit semester course “Quantitative Methods” taught University OKlahoma Fall 2022. Based course, objectives cookbook :able correctly identify variables falling different scales measurement.able correctly identify variables falling different scales measurement.able correctly identify appropriate techniques analyzing data presented variables different measurement characteristics.able correctly identify appropriate techniques analyzing data presented variables different measurement characteristics.able understand assumptions associated different statistical tests.able understand assumptions associated different statistical tests.able set manage databases containing variables.able set manage databases containing variables.able carry statistical analyses data using R.able carry statistical analyses data using R.able correctly interpret results statistical analyses.able correctly interpret results statistical analyses.able distinguish null alternative (research) hypotheses.able distinguish null alternative (research) hypotheses.able distinguish directional non-directional hypothesis.able distinguish directional non-directional hypothesis.understand concepts “statistical significance” “effect size”.understand concepts “statistical significance” “effect size”.understand effects sampling (e.g., size, strategies) inferences concerning population estimates.understand effects sampling (e.g., size, strategies) inferences concerning population estimates.","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"acknolwedgement","chapter":"Preface","heading":"0.1 Acknolwedgement","text":"like thank professor Dr C providing wonderful opportunity ocmpile resource materials R.","code":""},{"path":"preface.html","id":"conventions-used-in-the-book","chapter":"Preface","heading":"0.2 Conventions Used in the Book","text":"Code chunks presented typical Markdown format , code output :{runif(n = 20, min = 0, max = 100)}Finally, R version currently using:","code":"\nversion\n#>                _                                \n#> platform       x86_64-w64-mingw32               \n#> arch           x86_64                           \n#> os             mingw32                          \n#> crt            ucrt                             \n#> system         x86_64, mingw32                  \n#> status                                          \n#> major          4                                \n#> minor          2.2                              \n#> year           2022                             \n#> month          10                               \n#> day            31                               \n#> svn rev        83211                            \n#> language       R                                \n#> version.string R version 4.2.2 (2022-10-31 ucrt)\n#> nickname       Innocent and Trusting"},{"path":"preface.html","id":"rdrr-live-r-console","chapter":"Preface","heading":"0.3 RDRR (Live R console)","text":"","code":""},{"path":"basic-statistical-concepts.html","id":"basic-statistical-concepts","chapter":"1 Basic Statistical Concepts","heading":"1 Basic Statistical Concepts","text":"","code":""},{"path":"basic-statistical-concepts.html","id":"data-types","chapter":"1 Basic Statistical Concepts","heading":"1.1 Data Types","text":"Data types idea computer science program shares similar nomenclature case statistics. Data broadly classified constant variables terms nature execution analysis statistical program.Constant kind data types changed program analysis. eg, value alpha (alpha) always kept constant.Variables data types changed multiple values program.","code":""},{"path":"basic-statistical-concepts.html","id":"types-of-variable","chapter":"1 Basic Statistical Concepts","heading":"1.2 Types of variable","text":"Quantitative Variables (Continuous Discrete):\nContinuous Variables: Variables can take value within range, typically measured continuous scale. Example: Height, weight, temperature.\nDiscrete Variables: Variables can take specific values, usually whole numbers counts. Example: Number students class, number books library.\nQuantitative Variables (Continuous Discrete):Continuous Variables: Variables can take value within range, typically measured continuous scale. Example: Height, weight, temperature.Continuous Variables: Variables can take value within range, typically measured continuous scale. Example: Height, weight, temperature.Discrete Variables: Variables can take specific values, usually whole numbers counts. Example: Number students class, number books library.Discrete Variables: Variables can take specific values, usually whole numbers counts. Example: Number students class, number books library.Qualitative Variables (Nominal Ordinal):\nNominal Variables: Variables represent categories without inherent order. Example: Gender (male female), types food (vegetarian non-vegetarian).\nOrdinal Variables: Variables represent categories natural order ranking. Example: Education level (elementary, high school, college), customer satisfaction ratings (poor, average, excellent).\n                   VARIABLES\n                       |\n            +----------+-----------+\n            |                      |\n      Quantitative           Qualitative\n            |                      |\n     +------+-------+      +-------+-------+\n     |              |      |               |\nContinuous    Discrete   Nominal      Ordinal\nUnderstanding types variables crucial guides selection appropriate statistical techniques data analysis.\nQualitative Variables (Nominal Ordinal):Nominal Variables: Variables represent categories without inherent order. Example: Gender (male female), types food (vegetarian non-vegetarian).Nominal Variables: Variables represent categories without inherent order. Example: Gender (male female), types food (vegetarian non-vegetarian).Ordinal Variables: Variables represent categories natural order ranking. Example: Education level (elementary, high school, college), customer satisfaction ratings (poor, average, excellent).\n                   VARIABLES\n                       |\n            +----------+-----------+\n            |                      |\n      Quantitative           Qualitative\n            |                      |\n     +------+-------+      +-------+-------+\n     |              |      |               |\nContinuous    Discrete   Nominal      Ordinal\nUnderstanding types variables crucial guides selection appropriate statistical techniques data analysis.Ordinal Variables: Variables represent categories natural order ranking. Example: Education level (elementary, high school, college), customer satisfaction ratings (poor, average, excellent).Understanding types variables crucial guides selection appropriate statistical techniques data analysis.","code":"                   VARIABLES\n                       |\n            +----------+-----------+\n            |                      |\n      Quantitative           Qualitative\n            |                      |\n     +------+-------+      +-------+-------+\n     |              |      |               |\nContinuous    Discrete   Nominal      Ordinal"},{"path":"basic-statistical-concepts.html","id":"types-of-scales-of-measurement-of-variables","chapter":"1 Basic Statistical Concepts","heading":"1.3 Types of scales of measurement of variables","text":"Four different types scales measurement presented table .Understanding scales measurement important helps determine appropriate statistical techniques interpretations data.","code":""},{"path":"r-basics.html","id":"r-basics","chapter":"2 R Basics","heading":"2 R Basics","text":"sections covers everything need get run statistical analysis using R. Just like programming language, R also base package Integrated Development Environment. Base package need run R code computer. R Studio IDE developed specifically focussing development R programs packages.","code":""},{"path":"r-basics.html","id":"installing-r-base-package.","chapter":"2 R Basics","heading":"2.1 Installing R base package.","text":"R base package can downloaded official website R. , enter inside website select package operating system, download file install . ensure R successfully installed, able run command prompt terminal using R command. Type q() quit R console.","code":"$ R\n\nR version 4.2.1 (2022-06-23 ucrt) -- \"Funny-Looking Kid\"\nCopyright (C) 2022 The R Foundation for Statistical Computing\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n> q()"},{"path":"r-basics.html","id":"download-r-studio","chapter":"2 R Basics","heading":"2.1.1 Download R studio","text":"Well, need everything command terminal. R community also fully fledged development environment called R Studio free use user friendly work R. can download R studio .tutorial help understand basic overview components R studio.","code":""},{"path":"r-basics.html","id":"r-packages","chapter":"2 R Basics","heading":"2.2 R Packages","text":"R simply statistically programming language, R packages developed R community one key reason robustness, reproducibility flexibility. Many statistics programmers developed 100s packages can run even complex statistics functions single line code.","code":""},{"path":"r-basics.html","id":"r-console","chapter":"2 R Basics","heading":"2.3 R Console","text":"","code":""},{"path":"r-basics.html","id":"getting-help","chapter":"2 R Basics","heading":"2.4 Getting Help","text":"useful syntax ask help","code":"{Get help for an object, in this case for the –-plot– function. \n?plot  #You can also type: help(plot)\n\n#Search the help pages for anything that has the word \"regression\". \n??regression #You can also type:  help.search(\"regression\")\n\n#Search the word \"age\" in the objects available in the current R session.\n apropos(\"age\")\nhelp(package=car) # View documentation in package ‘car’. You can also type: library(help=\"car“)\nhelp(DataABC) # Access codebook for a dataset called ‘DataABC’ in the package ABC\nargs(log) # Description of the command.}"},{"path":"r-basics.html","id":"r-community-and-resources","chapter":"2 R Basics","heading":"2.5 R Community and Resources","text":"R huge community developers supporters. Following resources may useful move ahead research experiments.","code":""},{"path":"r-basics.html","id":"documentation-websites","chapter":"2 R Basics","heading":"2.5.1 Documentation / Websites","text":"","code":""},{"path":"r-basics.html","id":"books","chapter":"2 R Basics","heading":"2.5.2 Books","text":"","code":""},{"path":"r-basics.html","id":"website","chapter":"2 R Basics","heading":"2.5.3 Website","text":"","code":""},{"path":"r-basics.html","id":"cheatsheet","chapter":"2 R Basics","heading":"2.5.4 Cheatsheet","text":"","code":""},{"path":"loading-data-in-r.html","id":"loading-data-in-r","chapter":"3 Loading Data in R","heading":"3 Loading Data in R","text":"Data set can directly imported can entered manually directly R ans save R data file also. Lets see can manually enter save import different data formats R Studio.","code":""},{"path":"loading-data-in-r.html","id":"entering-data-in-r","chapter":"3 Loading Data in R","heading":"3.1 Entering Data in R","text":"can start working R right away entering data R. enter numerical data manually, c (stands ‘column’) command used.Similarly, categorical data can also entered using quotation marks.","code":"  age <- c(45, 23, 36, 29)\n    gpa <- c(\"A+\", \"A\", \"B+\", \"B\")\n  "},{"path":"loading-data-in-r.html","id":"importing-csv-file","chapter":"3 Loading Data in R","heading":"3.2 Importing CSV file","text":"read command function R used read data files. read CSV file, can simply move CSV file working directory load file using read.csv command. need readr package read CSV file., csv1 name assigned CSV file R environment. using variable name whenever want work csv file imported.","code":"'''library (readr)\n  csv1 <- read.csv(\"records.csv\")\n  \n  #To view the structure\n  str(csv1)\n  \n  #To view the CSV file\n  csv1\n  '''"},{"path":"loading-data-in-r.html","id":"importing-spss-and-stata-file","chapter":"3 Loading Data in R","heading":"3.3 Importing SPSS and STATA file","text":"R also package called ‘haven’ helps us read SPSS STATA data files easily R. installing haven package, use read_sav command import SPSS file.Note: seems like using \\ instead  writing path name prevent error : Error: '\\U' used without hex digits character string starting \"'C:\\U\"1","code":"  #Install package\n  install.packages('haven')\n  \n  #Load the package and read SPSS data file\n  \n  library(haven)\n  savdata1 <- read_sav('C:\\\\Users\\\\para\\\\Downloads\\\\ancova.sav')\n  \n  #To verify the file has been imported successfully.\n  savdata1\n  \n  #Load the package and read STATA data file\n  \n  library(haven)\n  dtadata1 <- read_dta('C:\\\\Users\\\\para\\\\Downloads\\\\ancovastata.dta')\n  \n  #To verify the file has been imported successfully.\n  dtadata1\n  "},{"path":"loading-data-in-r.html","id":"importing-excel-file","chapter":"3 Loading Data in R","heading":"3.4 Importing Excel File","text":"readxl package used read excel file R environment.R comprehensive packages import multiple statistical systems. packages include foreign, readdta1 etc. Find Data Import Export R .","code":" #Install package\n  install.packages('readxl')\n  \n  #Load the package and read data\n  \n  library(readxl)\n  xlsdata1 <- read_excel('C:\\\\Users\\\\para\\\\Downloads\\\\ancova.xls')\n  \n  #To verify the file has been imported successfully.\n  xlsdata1\n  "},{"path":"data-representation.html","id":"data-representation","chapter":"4 Data Representation","heading":"4 Data Representation","text":"## Frequency Tables: frequency table displays number occurrences (frequencies) category value data set. particularly useful summarizing categorical data discrete numerical data.","code":"\n# Example data\ndata <- c(\"A\", \"A\", \"B\", \"A\", \"B\", \"C\", \"C\", \"A\", \"B\", \"C\")\n\n# Frequency table\ntable(data)\n#> data\n#> A B C \n#> 4 3 3"},{"path":"data-representation.html","id":"histograms","chapter":"4 Data Representation","heading":"4.1 Histograms:","text":"Histograms used visualize distribution continuous discrete numerical data. display data using intervals (bins) along x-axis frequency observations within bin y-axis.","code":"\n# Example data\ndata_numeric <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n# Histogram\nhist(data_numeric)"},{"path":"data-representation.html","id":"bar-graphs","chapter":"4 Data Representation","heading":"4.2 Bar Graphs:","text":"Bar graphs used displaying categorical data. category represented bar, height (length) bar indicates frequency count category.","code":"\n#Bar graph\nbarplot(table(data))"},{"path":"data-representation.html","id":"pie-charts","chapter":"4 Data Representation","heading":"4.3 Pie Charts:","text":"Pie charts represent categorical data slices circle. size slice proportional frequency category. Pie charts useful visualizing relative proportions categories.","code":"\n#Pie chart\npie(table(data))"},{"path":"data-representation.html","id":"box-plots","chapter":"4 Data Representation","heading":"4.4 Box Plots:","text":"Box plots used visualizing distribution continuous discrete numerical data. show median, quartiles, outliers data, providing compact informative representation data distribution.data representation techniques serves different purpose suited different types data. understanding use method, can effectively communicate data insights findings.","code":"\nboxplot(data_numeric)"},{"path":"describing-data-in-r.html","id":"describing-data-in-r","chapter":"5 Describing Data in R","heading":"5 Describing Data in R","text":"","code":""},{"path":"describing-data-in-r.html","id":"central-tendency","chapter":"5 Describing Data in R","heading":"5.1 Central Tendency:","text":"Central tendency measures provide single value represents center “typical” value dataset. primary measures central tendency mean, median, mode.","code":""},{"path":"describing-data-in-r.html","id":"mean","chapter":"5 Describing Data in R","heading":"5.1.1 Mean","text":"mean, often referred average, sum data points divided total number data points. mean sensitive extreme values (outliers) may always represent true center data.","code":""},{"path":"describing-data-in-r.html","id":"median","chapter":"5 Describing Data in R","heading":"5.1.2 Median","text":"median middle value dataset sorted ascending descending order. dataset odd number data points, median middle value; even number data points, median average two middle values. median less sensitive extreme values compared mean.","code":""},{"path":"describing-data-in-r.html","id":"mode","chapter":"5 Describing Data in R","heading":"5.1.3 Mode","text":"mode value occurs frequently dataset. dataset can one mode (multimodal) mode (value occurs ). mode can used numerical categorical data.calculate measures using “psych” package R, follow steps:Install load “psych” package:calculate mean, median mode.“psych” package provides “describe()” function, calculates various summary statistics, including mode. mean median functions available base R package, can use without loading “psych” package.","code":"\ninstall.packages(\"psych\")\nlibrary(psych)\n# Example data\ndata <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n# Mean\nmean(data)\n#> [1] 5\n\n# Median\nmedian(data)\n#> [1] 5\n\n# Mode\npsych::describe(data)$mode\n#> NULL"},{"path":"describing-data-in-r.html","id":"measures-of-dispersion","chapter":"5 Describing Data in R","heading":"5.2 Measures of Dispersion","text":"primary measures dispersion :","code":""},{"path":"describing-data-in-r.html","id":"range","chapter":"5 Describing Data in R","heading":"5.2.1 Range:","text":"range difference maximum minimum values dataset. gives basic idea spread data sensitive outliers provide information distribution’s shape.\nFormula: Range = Max(X) - Min(X)","code":""},{"path":"describing-data-in-r.html","id":"interquartile-range-iqr","chapter":"5 Describing Data in R","heading":"5.2.2 Interquartile Range (IQR):","text":"IQR difference first quartile (Q1, 25th percentile) third quartile (Q3, 75th percentile) dataset. describes spread middle 50% data less sensitive outliers range.\nFormula: IQR = Q3 - Q1","code":""},{"path":"describing-data-in-r.html","id":"variance","chapter":"5 Describing Data in R","heading":"5.2.3 Variance:","text":"variance average squared differences data point mean. measures degree data points deviate mean. variance influenced outliers expressed squared units.\nFormula (population variance): σ² = Σ(X - μ)² / N\nFormula (sample variance): s² = Σ(X - x̄)² / (n - 1)","code":""},{"path":"describing-data-in-r.html","id":"standard-deviation","chapter":"5 Describing Data in R","heading":"5.2.4 Standard Deviation:","text":"standard deviation square root variance. measures average deviation data points mean expressed units data. Like variance, sensitive outliers.\nFormula (population standard deviation): σ = √σ²\nFormula (sample standard deviation): s = √s²","code":""},{"path":"describing-data-in-r.html","id":"calculating-measures-of-dispersion-using-r","chapter":"5 Describing Data in R","heading":"5.2.5 Calculating Measures of Dispersion Using R","text":"can use psych pakcage calculate measures dispersion.","code":"\n# Example data\ndata <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n# Range\nmax(data) - min(data)\n#> [1] 8\n\n# IQR\nIQR(data)\n#> [1] 4\n\n# Variance\nvar(data)\n#> [1] 7.5\n\n# Standard deviation\nsd(data)\n#> [1] 2.738613"},{"path":"normal-distribution.html","id":"normal-distribution","chapter":"6 Normal Distribution","heading":"6 Normal Distribution","text":"Normal distribution continuous, symmetric, bell-shaped\ndistribution defined two parameters: mean (μ) \nstandard deviation (σ).mean (μ) determines center distribution, standard\ndeviation (σ) controls spread dispersion data.\nApproximately 68% data falls within one standard deviation \nmean, 95% falls within two standard deviations, 99.7% falls\nwithin three standard deviations. known Empirical Rule \n68-95-99.7 rule.probability density function (PDF) Normal distribution \ngiven :f(x) = (1 / (σ * √(2π))) * e^(-1/2 * ((x - μ) / σ)^2):f(x) probability density point x μ mean \ndistribution σ standard deviation distribution e \nbase natural logarithm (approximately 2.718) π \nmathematical constant Pi (approximately 3.141) help visualize \nNormal distribution, consider following example using R:R code generates plot Normal distribution mean 0\nstandard deviation 1, also known standard\nNormal distribution Z-distribution. plot shows \nbell-shaped curve distribution, illustrating data \nsymmetric around mean decreases move away \ncenter.ggplot2 powerful package draw graphics. implements \ngrammar graphics (hence name). can find official\ndocumentation ggplot2 : https://ggplot2.tidyverse.org can\nalso use ggplot2 create different descriptive graphs create\nearlier also customize want.Understanding Normal distribution crucial statistics \nmany statistical tests procedures based assumption \nNormality. also essential , practice, many naturally\noccurring phenomena approximately follow Normal distribution.","code":"\n# Load required libraries\nlibrary(ggplot2)\n\n# Define the mean and standard deviation\nmean <- 0\nsd <- 1\n\n# Generate a sequence of x values\nx <- seq(-4, 4, length.out = 1000)\n\n# Calculate the probability density function for the x values\npdf <- dnorm(x, mean = mean, sd = sd)\n\n# Create the plot\nggplot() +\n  geom_line(aes(x, pdf), color = \"blue\") +\n  xlab(\"X\") +\n  ylab(\"Probability Density\") +\n  ggtitle(\"Normal Distribution (μ = 0, σ = 1)\") +\n  theme_minimal()"},{"path":"skewness-and-kurtosis.html","id":"skewness-and-kurtosis","chapter":"7 Skewness and Kurtosis","heading":"7 Skewness and Kurtosis","text":"Skewness Kurtosis two different measures shapes \ndistribution dataset qualitative methods.","code":""},{"path":"skewness-and-kurtosis.html","id":"skewness","chapter":"7 Skewness and Kurtosis","heading":"7.1 Skewness","text":"Skewness measure asymmetry distribution. describes\ndegree distribution deviates symmetric shape. \nskewness value 0 indicates perfectly symmetric distribution.\nPositive skewness indicates distribution longer tail \nright side, negative skewness indicates longer tail left\nside.","code":""},{"path":"skewness-and-kurtosis.html","id":"kurtosis","chapter":"7 Skewness and Kurtosis","heading":"7.2 Kurtosis","text":"Kurtosis measure “tailedness” “peakedness” \ndistribution. describes distribution’s tails peak compare\nnormal distribution. kurtosis value 0 indicates distribution\nsimilar shape normal distribution. Positive kurtosis\nindicates distribution heavier tails peaked shape \nnormal distribution, negative kurtosis indicates lighter tails\nless peaked shape.","code":""},{"path":"skewness-and-kurtosis.html","id":"generating-skewness-and-kurtosis-using-r","chapter":"7 Skewness and Kurtosis","heading":"7.3 Generating Skewness and Kurtosis using R","text":"can use psych package generate skewness Kurtosis.","code":""},{"path":"standard-scores.html","id":"standard-scores","chapter":"8 Standard Scores","heading":"8 Standard Scores","text":"Standard scores type transformed scores express individual data points dataset relative mean standard deviation dataset. Standard scores allow comparing scores across different distributions scales placing common scale. provide standardized measure position data point within distribution, taking account average value (mean) spread (standard deviation) data.","code":""},{"path":"standard-scores.html","id":"z--score","chapter":"8 Standard Scores","heading":"8.1 Z- Score","text":"z-score type standard score calculated subtracting mean (μ) individual data point (X) dividing result standard deviation (σ):z = (X - μ) / σA z-score represents many standard deviations data point mean. positive z-score indicates data point mean, negative z-score indicates mean. z-score 0 corresponds mean distribution.educational settings, z-scores can used various ways, :Comparing student performance: Z-scores enable comparison student scores across different tests grading scales standardizing scores. allows educators make informed decisions student performance identify students might need additional support resources.Identifying outliers: Z-scores can help identify students perform exceptionally well poorly compared group mean. Outliers can provide insights effectiveness teaching methods, identify areas improvement, recognize exceptional talent.Normalizing grades: cases distribution grades skewed, converting raw scores z-scores can provide equitable assessment student performance. Z-scores can converted percentiles, represent percentage students scored lower particular student, providing standardized ranking within group.calculate z-scores R, can use following code:understanding utilizing z-scores education, educators researchers can make informed decisions student performance, compare results across different assessments, identify patterns trends student achievement.","code":"\n# Example data\ndata <- c(60, 65, 70, 75, 80, 85, 90)\n\n# Calculate the mean and standard deviation\nmean_data <- mean(data)\nsd_data <- sd(data)\n\n# Calculate z-scores\nz_scores <- (data - mean_data) / sd_data\n\nz_scores\n#> [1] -1.3887301 -0.9258201 -0.4629100  0.0000000  0.4629100\n#> [6]  0.9258201  1.3887301"},{"path":"standard-scores.html","id":"t--scores","chapter":"8 Standard Scores","heading":"8.2 T- Scores","text":"T-score type standard score used transform standardize individual data points dataset. T-scores similar z-scores, use different scaling factor place scores specific scale. T-scores especially helpful comparing scores across different distributions scales.T-score calculated subtracting mean (μ) individual data point (X), dividing result standard deviation (σ), multiplying result scaling factor (usually 10) adding constant (usually 50):T = ((X - μ) / σ) * 10 + 50The scaling factor 10 constant 50 ensure T-scores mean 50 standard deviation 10. T-score transformation preserves shape original distribution relative positions data points.T-scores can used various ways:Comparing scores across different tests scales: T-scores enable comparison scores different tests grading scales standardizing scores common scale. allows meaningful comparisons helps decision-making considering different assessments.Norm-referenced interpretation: T-scores often used standardized testing provide norm-referenced interpretation test scores. enables comparison individual’s performance performance reference group (e.g., age grade peers).Clinical psychological assessments: T-scores commonly used clinical psychological assessments interpret scores various tests questionnaires, allowing practitioners compare individual’s performance symptoms normative sample.calculate T-scores R, can use following code:understanding utilizing T-scores, can make informed decisions individual performance, compare results across different assessments, identify patterns trends standardized manner.","code":"\n# Example data\ndata <- c(60, 65, 70, 75, 80, 85, 90)\n\n# Calculate the mean and standard deviation\nmean_data <- mean(data)\nsd_data <- sd(data)\n\n# Calculate T-scores\nt_scores <- ((data - mean_data) / sd_data) * 10 + 50"},{"path":"probability-and-inference.html","id":"probability-and-inference","chapter":"9 Probability and Inference","heading":"9 Probability and Inference","text":"","code":""},{"path":"probability-and-inference.html","id":"probability","chapter":"9 Probability and Inference","heading":"9.1 Probability:","text":"Probability numerical measure likelihood particular event occur. ranges 0 1, 0 meaning event impossible 1 meaning event certain. Probabilities can represented graphically using bar plots pie charts.","code":""},{"path":"probability-and-inference.html","id":"sample-space","chapter":"9 Probability and Inference","heading":"9.2 Sample Space:","text":"sample space set possible outcomes given experiment event. example, coin toss experiment, sample space {Heads, Tails}. sample space can represented using Venn diagrams tree diagrams.","code":""},{"path":"probability-and-inference.html","id":"conditional-probability","chapter":"9 Probability and Inference","heading":"9.3 Conditional Probability:","text":"Conditional probability refers probability event occurring given another event already occurred. can represented graphically using Venn diagrams, show intersections events.","code":""},{"path":"probability-and-inference.html","id":"independence","chapter":"9 Probability and Inference","heading":"9.4 Independence:","text":"Two events independent occurrence one event affect probability event. Graphically, independence can visualized using Venn diagrams probability tables, probability intersection two events equal product individual probabilities.","code":""},{"path":"probability-and-inference.html","id":"bayes-theorem","chapter":"9 Probability and Inference","heading":"9.5 Bayes’ Theorem:","text":"Bayes’ theorem powerful tool updating probability event based new evidence. can visualized using tree diagrams probability tables, show updated probabilities taking account new evidence.","code":""},{"path":"probability-and-inference.html","id":"discrete-and-continuous-probability-distributions","chapter":"9 Probability and Inference","heading":"9.6 Discrete and Continuous Probability Distributions:","text":"Discrete probability distributions describe probabilities outcomes discrete random variables (e.g., number heads coin tosses), continuous probability distributions describe probabilities outcomes continuous random variables (e.g., height individuals). Discrete distributions can visualized using bar plots, continuous distributions can visualized using probability density functions cumulative distribution functions.#Sampling distributionA sampling distribution probability distribution sample statistic (e.g., sample mean, sample proportion) obtained population. helps understand variability sample statistic likelihood obtaining different sample statistics population.","code":""},{"path":"probability-and-inference.html","id":"central-limit-theorem","chapter":"9 Probability and Inference","heading":"9.7 Central Limit Theorem","text":"CLT states , large enough sample size (usually n ≥ 30), distribution sample means approaches normal distribution, regardless shape population distribution. mean sampling distribution equal population mean (μ), standard deviation (standard error) equal population standard deviation (σ) divided square root sample size (n).","code":"\n# Load required libraries\nlibrary(ggplot2)\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Define population parameters\npopulation_mean <- 10\npopulation_sd <- 5\n\n# Define sample size and number of samples\nsample_size <- 50\nnum_samples <- 1000\n\n# Generate random samples and calculate sample means\nsample_means <- replicate(num_samples, mean(rnorm(sample_size, mean = population_mean, sd = population_sd)))\n\n# Plot the distribution of sample means\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"lightblue\", color = \"black\") +\n  geom_density(color = \"blue\") +\n  ggtitle(\"Sampling Distribution of the Mean\") +\n  xlab(\"Sample Means\") +\n  ylab(\"Density\") +\n  theme_minimal()\n#> Warning: The dot-dot notation (`..density..`) was deprecated in\n#> ggplot2 3.4.0.\n#> ℹ Please use `after_stat(density)` instead."},{"path":"probability-and-inference.html","id":"confidence-intervals","chapter":"9 Probability and Inference","heading":"9.8 Confidence Intervals","text":"Confidence intervals range values within true population parameter likely fall, specified level confidence (e.g., 95%). Confidence intervals provide estimate precision uncertainty sample statistic.","code":"\n# Define the sample data\nsample_data <- c(12, 15, 18, 20, 22, 24, 25, 28, 30, 32)\n\n# Calculate the sample mean and standard deviation\nsample_mean <- mean(sample_data)\nsample_sd <- sd(sample_data)\n\n# Calculate the standard error\nstandard_error <- sample_sd / sqrt(length(sample_data))\n\n# Calculate the 95% confidence interval\nalpha <- 0.05\ncritical_value <- qnorm(1 - alpha / 2)\nmargin_of_error <- critical_value * standard_error\nconfidence_interval <- c(sample_mean - margin_of_error, sample_mean + margin_of_error)"},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"10 Hypothesis Testing","heading":"10 Hypothesis Testing","text":"Hypothesis testing method used make decisions population parameters based sample data.","code":""},{"path":"hypothesis-testing.html","id":"hypothesis","chapter":"10 Hypothesis Testing","heading":"10.1 Hypothesis","text":"hypothesis educated guess statement relationship variables characteristics population. hypothesis testing, two main hypotheses:","code":""},{"path":"hypothesis-testing.html","id":"null-hypothesis-h0","chapter":"10 Hypothesis Testing","heading":"10.1.1 Null hypothesis (H0):","text":"hypothesis states effect relationship variables. typically hypothesis researcher wants disprove.","code":""},{"path":"hypothesis-testing.html","id":"alternative-hypothesis-h1","chapter":"10 Hypothesis Testing","heading":"10.1.2 Alternative hypothesis (H1):","text":"hypothesis states effect relationship variables. hypothesis researcher wants prove provide evidence .","code":""},{"path":"hypothesis-testing.html","id":"decision-type-error","chapter":"10 Hypothesis Testing","heading":"10.2 Decision Type Error","text":"performing hypothesis testing, two types decision errors:Type Error (α): error occurs null hypothesis rejected actually true. words, ’s false positive. probability committing Type error denoted significance level (α), typically set 0.05 0.01.\nType II Error (β): error occurs null hypothesis rejected actually false. words, ’s false negative. probability committing Type II error denoted β. power test (1 - β) measures ability test detect effect truly exists.\ngraphical representation types decision errors:Hypothesis Testing ErrorsThis table represents different outcomes making decisions based hypothesis testing. columns represent reality (.e., whether null hypothesis true false), rows represent decision made based hypothesis test (.e., whether reject reject null hypothesis). cells show types decision errors (Type Type II errors) correct decisions.","code":"|                  | Null Hypothesis (H0) is True | Null Hypothesis (H0) is False |\n|------------------|------------------------------|-------------------------------|\n| Reject H0        | Type I Error (α)             | Correct Decision (1 - β)      |\n| Fail to Reject H0| Correct Decision (1 - α)     | Type II Error (β)             |"},{"path":"hypothesis-testing.html","id":"level-of-signficance","chapter":"10 Hypothesis Testing","heading":"10.3 Level of Signficance","text":"level significance critical component hypothesis testing sets threshold determining whether observed effect statistically significant .level significance denoted Greek letter α (alpha) represents probability making Type error. Type error occurs reject null hypothesis (H0) actually true. choosing level significance, researchers define risk willing take rejecting true null hypothesis. Common levels significance 0.05 (5%) 0.01 (1%).better understand role level significance hypothesis testing, let’s consider following steps:Formulate null hypothesis (H0) alternative hypothesis (H1): null hypothesis typically states effect relationship variables, alternative hypothesis states effect relationship.Choose level significance (α): Determine threshold probability making Type error. example, α set 0.05, 5% chance rejecting true null hypothesis.Perform statistical test calculate test statistic: test statistic calculated using sample data, helps determine far observed sample mean hypothesized population mean. case single mean, one-sample t-test commonly used, test statistic t-value.Determine critical value p-value: Compare calculated test statistic critical value p-value (probability value) make decision null hypothesis. critical value threshold value depends chosen level significance distribution test statistic. p-value represents probability obtaining test statistic extreme extreme observed test statistic assumption null hypothesis true.Make decision: test statistic extreme critical value, p-value less level significance (α), reject null hypothesis. Otherwise, fail reject null hypothesis.","code":""},{"path":"hypothesis-testing.html","id":"t-statistic","chapter":"10 Hypothesis Testing","heading":"10.4 T-statistic","text":"t-statistic standardized measure used hypothesis testing compare observed sample mean hypothesized population mean. takes account sample mean, hypothesized population mean, standard error mean. Mathematically, t-statistic can calculated using following formula:t = (X̄ - μ) / (s / √n):t t-statistic\nX̄ sample mean\nμ hypothesized population mean\ns sample standard deviation\nn sample size","code":""},{"path":"hypothesis-testing.html","id":"t-distribution","chapter":"10 Hypothesis Testing","heading":"10.4.1 T-distribution","text":"t-distribution, also known Student’s t-distribution, probability distribution used population standard deviation unknown sample size small. similar normal distribution thicker tails, accounts increased variability due using sample standard deviation estimate population standard deviation. shape t-distribution depends degrees freedom (df), related sample size (df = n - 1). sample size increases, t-distribution approaches normal distribution.calculate t-statistic R, can use following code:perform one-sample t-test R, calculates t-statistic p-value automatically, can use t.test() function:","code":"\n# Sample data\ndata <- c(12, 14, 16, 18, 20)\n\n# Hypothesized population mean\nhypothesized_mean <- 15\n\n# Calculate the sample mean, standard deviation, and size\nsample_mean <- mean(data)\nsample_sd <- sd(data)\nsample_size <- length(data)\n\n# Calculate the t-statistic\nt_statistic <- (sample_mean - hypothesized_mean) / (sample_sd / sqrt(sample_size))\n\n# Print the t-statistic\nprint(t_statistic)\n#> [1] 0.7071068\n# Perform a one-sample t-test\nt_test_result <- t.test(data, mu = hypothesized_mean)\n\n# Print the t-test result\nprint(t_test_result)\n#> \n#>  One Sample t-test\n#> \n#> data:  data\n#> t = 0.70711, df = 4, p-value = 0.5185\n#> alternative hypothesis: true mean is not equal to 15\n#> 95 percent confidence interval:\n#>  12.07351 19.92649\n#> sample estimates:\n#> mean of x \n#>        16"},{"path":"hypothesis-testing.html","id":"intepreting-normality-evidence","chapter":"10 Hypothesis Testing","heading":"10.4.2 Intepreting Normality Evidence","text":"using t-test, assumption normality important. data follow normal distribution ensure validity test results. assess normality data, can use visual methods (histograms, Q-Q plots) statistical tests (e.g., Shapiro-Wilk test).important t-test assumes data follow normal distribution, verifying assumption helps ensure validity test results.generate normality evidence performing t-test, can use following methods:Visual methods: Histograms Q-Q plots can provide visual assessment normality data.Statistical tests: Shapiro-Wilk test Kolmogorov-Smirnov test commonly used test normality. tests generate p-values, can compared chosen significance level (e.g., 0.05) determine data deviate significantly normality.R, can create histogram Q-Q plot using following code:Create histogram Q-Q plot:Perform Shapiro-Wilk test:interpret normality evidence, follow guidelines:Visual methods: Inspect histogram Q-Q plot. histogram roughly bell-shaped points Q-Q plot fall approximately reference line, data can considered approximately normally distributed.Statistical tests: Check p-values normality tests. p-value greater chosen significance level (e.g., 0.05), null hypothesis (.e., data follow normal distribution) rejected. suggests data deviate significantly normality.Keep mind single method foolproof, ’s often good idea use combination visual statistical methods assess normality. data appear non-normal, might consider using non-parametric alternatives t-test transforming data achieve normality.","code":"\n# Load required libraries\nlibrary(ggplot2)\n\n# Sample data\ndata <- c(12, 14, 16, 18, 20)\n\n# Create a histogram\nggplot(data.frame(data), aes(data)) +\n  geom_histogram(binwidth = 1, color = \"black\", fill = \"white\") +\n  theme_minimal()\n\n# Create a Q-Q plot\nqqnorm(data)\nqqline(data, col = \"red\")\n# Perform the Shapiro-Wilk test\nshapiro_test_result <- shapiro.test(data)\n\n# Print the test result\nprint(shapiro_test_result)\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  data\n#> W = 0.98676, p-value = 0.9672"},{"path":"hypothesis-testing.html","id":"statistical-power","chapter":"10 Hypothesis Testing","heading":"10.5 Statistical Power","text":"Statistical power probability correctly rejecting null hypothesis false, means committing Type II error. Power influenced factors sample size, effect size, chosen significance level (α). Power analysis helps researchers determine appropriate sample size needed achieve desired level power, typically 0.8 higher.perform power analysis R, can use pwr package, provides set functions power calculations various statistical tests, including t-test.’s step--step procedure generating testing power using R:Install load pwr package:Define parameters power analysis. need specify effect size (Cohen’s d), sample size, significance level (α):Use pwr.t.test() function calculate power one-sample t-test:output show calculated power, sample size, effect size, significance level. power desired level (e.g., 0.8), can adjust sample size effect size recalculate power determine necessary changes achieving desired power level.’s essential consider practical implications effect size sample size planning study. large effect size may easier detect might occur frequently real-world situations. Conversely, small effect size might difficult detect may require larger sample size achieve adequate power.","code":"\n\n# Load the pwr package\nlibrary(pwr)\n#> Warning: package 'pwr' was built under R version 4.2.3\n# Define parameters for power analysis\neffect_size <- 0.8  # Cohen's d\nsample_size <- 20\nsignificance_level <- 0.05\n# Calculate the power for a one-sample t-test\npower_result <- pwr.t.test(n = 500,\n                           d = effect_size,\n                           sig.level = significance_level,\n                           type = \"one.sample\",\n                           alternative = \"two.sided\")\n\n# Print the power result\nprint(power_result)\n#> \n#>      One-sample t test power calculation \n#> \n#>               n = 500\n#>               d = 0.8\n#>       sig.level = 0.05\n#>           power = 1\n#>     alternative = two.sided"},{"path":"inferences-between-two-means.html","id":"inferences-between-two-means","chapter":"11 Inferences between two means","heading":"11 Inferences between two means","text":"chapter covers different topics related independent dependent samples t-test, including assumptions, procedures, interpretations.","code":""},{"path":"inferences-between-two-means.html","id":"independent-vs-dependent-samples","chapter":"11 Inferences between two means","heading":"11.1 Independent vs Dependent Samples","text":"table provides comprehensive comparison dependent independent samples, including definitions, examples, hypothesis testing, assumptions, statistical tests, effect size measures, R functions. understanding differences, can choose appropriate statistical test data interpret results correctly.","code":""},{"path":"inferences-between-two-means.html","id":"independent-samples-t-test","chapter":"11 Inferences between two means","heading":"11.2 Independent Samples t-test","text":"independent samples t-test used compare means two independent groups determine significant difference .independent samples t-test based following null (H₀) alternative (H₁) hypotheses:H₀: μ₁ = μ₂ (significant difference means two groups.)\nH₁: μ₁ ≠ μ₂ (significant difference means two groups.)\ntest statistic independent samples t-test t-value, calculated using following formula:t = (M₁ - M₂) / sqrt((s₁²/n₁) + (s₂²/n₂)):M₁ M₂ means two groups\ns₁² s₂² variances two groups\nn₁ n₂ sample sizes two groups\nt-value follows t-distribution degrees freedom (df) approximated following formula:df = min(n₁ - 1, n₂ - 1)t-value degrees freedom calculated, p-value can determined comparing t-value t-distribution appropriate degrees freedom. p-value less chosen significance level (e.g., 0.05), null hypothesis can rejected, indicating significant difference means two groups.","code":""},{"path":"inferences-between-two-means.html","id":"independent-t-test-using-r","chapter":"11 Inferences between two means","heading":"11.2.1 Independent t-test using R","text":"need data two independent groups, typically stored data frame one variable representing group membership another variable representing outcome interest.Perform independent samples t-test: Use t.test() function R, specifying formula data frame arguments.output t.test() function include t-value, degrees freedom, p-value, confidence interval difference means. p-value less chosen significance level (e.g., 0.05), can reject null hypothesis, concluding significant difference means two groups.#Covariance","code":"\n# Example data\ngroup <- c(\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"B\")\noutcome <- c(10, 12, 14, 16, 18, 20, 22, 24, 26, 28)\n\n# Create a data frame\ndata <- data.frame(group, outcome)\n# Perform the independent samples t-test\nt_test_result <- t.test(outcome ~ group, data = data)\n\n# Print the test result\nprint(t_test_result)\n#> \n#>  Welch Two Sample t-test\n#> \n#> data:  outcome by group\n#> t = -5, df = 8, p-value = 0.001053\n#> alternative hypothesis: true difference in means between group A and group B is not equal to 0\n#> 95 percent confidence interval:\n#>  -14.612008  -5.387992\n#> sample estimates:\n#> mean in group A mean in group B \n#>              14              24"},{"path":"correlation.html","id":"correlation","chapter":"12 Correlation","heading":"12 Correlation","text":"","code":""},{"path":"simple-linear-regression.html","id":"simple-linear-regression","chapter":"13 Simple Linear Regression","heading":"13 Simple Linear Regression","text":"","code":""},{"path":"multiple-regression.html","id":"multiple-regression","chapter":"14 Multiple Regression","heading":"14 Multiple Regression","text":"","code":""},{"path":"one-way-anova.html","id":"one-way-anova","chapter":"15 One way ANOVA","heading":"15 One way ANOVA","text":"","code":""},{"path":"tukeys-post-hoc-tests.html","id":"tukeys-post-hoc-tests","chapter":"16 Tukey’s post hoc tests","heading":"16 Tukey’s post hoc tests","text":"","code":""},{"path":"chi-square-tests.html","id":"chi-square-tests","chapter":"17 Chi Square Tests","heading":"17 Chi Square Tests","text":"","code":""},{"path":"chi-square-tests.html","id":"chi-square-goodness-of-fit-test","chapter":"17 Chi Square Tests","heading":"17.1 Chi Square Goodness of Fit Test","text":"","code":""},{"path":"chi-square-tests.html","id":"chi-sqaure-test-of-association","chapter":"17 Chi Square Tests","heading":"17.2 Chi Sqaure test of association","text":"","code":""},{"path":"g-power.html","id":"g-power","chapter":"18 G* Power","heading":"18 G* Power","text":"","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
